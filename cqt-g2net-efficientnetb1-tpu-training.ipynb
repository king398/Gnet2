{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install -q efficientnet"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 9.673051,
     "end_time": "2021-06-12T15:10:08.223254",
     "exception": false,
     "start_time": "2021-06-12T15:09:58.550203",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2021-07-05T09:47:17.269801Z",
     "iopub.execute_input": "2021-07-05T09:47:17.270290Z",
     "iopub.status.idle": "2021-07-05T09:47:27.151576Z",
     "shell.execute_reply.started": "2021-07-05T09:47:17.270197Z",
     "shell.execute_reply": "2021-07-05T09:47:27.150153Z"
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Asthetics\n",
    "import warnings\n",
    "import sklearn.exceptions\n",
    "\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.UndefinedMetricWarning)\n",
    "\n",
    "# General\n",
    "from kaggle_datasets import KaggleDatasets\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import cv2\n",
    "import random\n",
    "import shutil\n",
    "import math\n",
    "import re\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Visualizations\n",
    "from PIL import Image\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly.offline import iplot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.express as px\n",
    "% matplotlib inline\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Machine Learning\n",
    "# Pre Procesing\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "# Models\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import efficientnet.tfkeras as efn\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetB4\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow_addons.metrics import F1Score, FBetaScore\n",
    "from tensorflow_addons.callbacks import TQDMProgressBar\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "#Metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "\n",
    "print('TF', tf.__version__)\n",
    "\n",
    "# Random Seed Fixing\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "\n",
    "def seed_everything(seed=RANDOM_SEED):\n",
    "\tos.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\tnp.random.seed(seed)\n",
    "\trandom.seed(seed)\n",
    "\ttf.random.set_seed(seed)\n",
    "\n",
    "\n",
    "seed_everything()"
   ],
   "metadata": {
    "papermill": {
     "duration": 10.406747,
     "end_time": "2021-06-12T15:10:18.648284",
     "exception": false,
     "start_time": "2021-06-12T15:10:08.241537",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2021-07-05T09:47:27.153600Z",
     "iopub.execute_input": "2021-07-05T09:47:27.153954Z",
     "iopub.status.idle": "2021-07-05T09:47:37.597021Z",
     "shell.execute_reply.started": "2021-07-05T09:47:27.153910Z",
     "shell.execute_reply": "2021-07-05T09:47:37.596197Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": "TF 2.4.1\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# From https://www.kaggle.com/xhlulu/ranzcr-efficientnet-tpu-training\n",
    "def auto_select_accelerator():\n",
    "\tTPU_DETECTED = False\n",
    "\ttry:\n",
    "\t\ttpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "\t\ttf.config.experimental_connect_to_cluster(tpu)\n",
    "\t\ttf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "\t\tstrategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "\t\tprint(\"Running on TPU:\", tpu.master())\n",
    "\t\tTPU_DETECTED = True\n",
    "\texcept ValueError:\n",
    "\t\tstrategy = tf.distribute.get_strategy()\n",
    "\tprint(f\"Running on {strategy.num_replicas_in_sync} replicas\")\n",
    "\n",
    "\treturn strategy, TPU_DETECTED"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.02909,
     "end_time": "2021-06-12T15:10:18.696808",
     "exception": false,
     "start_time": "2021-06-12T15:10:18.667718",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2021-07-05T09:47:37.599013Z",
     "iopub.execute_input": "2021-07-05T09:47:37.599595Z",
     "iopub.status.idle": "2021-07-05T09:47:37.606065Z",
     "shell.execute_reply.started": "2021-07-05T09:47:37.599559Z",
     "shell.execute_reply": "2021-07-05T09:47:37.605065Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CFG"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.017986,
     "end_time": "2021-06-12T15:10:18.733021",
     "exception": false,
     "start_time": "2021-06-12T15:10:18.715035",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Model Params\n",
    "KFOLDS = 4\n",
    "IMG_SIZES = [256] * KFOLDS\n",
    "BATCH_SIZES = [64] * KFOLDS\n",
    "EPOCHS = [30] * KFOLDS\n",
    "EFF_NETS = [1] * KFOLDS  # WHICH EFFICIENTNET B? TO USE\n",
    "\n",
    "AUG = True\n",
    "MIX_UP_P = 0.1\n",
    "S_SHIFT = 0.0\n",
    "T_SHIFT = 0.0\n",
    "R_ANGLE = 0 / 180 * np.pi\n",
    "\n",
    "# Model Eval Params\n",
    "DISPLAY_PLOT = True\n",
    "\n",
    "# Inference Params\n",
    "WGTS = [1 / KFOLDS] * KFOLDS"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.030113,
     "end_time": "2021-06-12T15:10:18.781524",
     "exception": false,
     "start_time": "2021-06-12T15:10:18.751411",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2021-07-05T09:47:37.607940Z",
     "iopub.execute_input": "2021-07-05T09:47:37.608544Z",
     "iopub.status.idle": "2021-07-05T09:47:37.622181Z",
     "shell.execute_reply.started": "2021-07-05T09:47:37.608460Z",
     "shell.execute_reply": "2021-07-05T09:47:37.620569Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "strategy, TPU_DETECTED = auto_select_accelerator()\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "REPLICAS = strategy.num_replicas_in_sync"
   ],
   "metadata": {
    "papermill": {
     "duration": 5.397929,
     "end_time": "2021-06-12T15:10:24.197997",
     "exception": false,
     "start_time": "2021-06-12T15:10:18.800068",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2021-07-05T09:47:37.624012Z",
     "iopub.execute_input": "2021-07-05T09:47:37.624633Z",
     "iopub.status.idle": "2021-07-05T09:47:37.645355Z",
     "shell.execute_reply.started": "2021-07-05T09:47:37.624586Z",
     "shell.execute_reply": "2021-07-05T09:47:37.643654Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": "Running on 1 replicas\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "files_train_g = []\n",
    "for i, k in tqdm([(0, 1), (2, 3), (4, 5), (6, 7), (8, 9), (10, 11), (12, 13), (14, 15)]):\n",
    "\tGCS_PATH = \"gs://kds-55637b5723913dd2aa41ad441683c14cb5d74b82388699ddbc7a358a\"\n",
    "\tfiles_train_g.extend(np.sort(np.array(tf.io.gfile.glob(GCS_PATH + '/train*.tfrec'))).tolist())\n",
    "num_train_files = len(files_train_g)\n",
    "print(files_train_g)\n",
    "print('train_files:', num_train_files)"
   ],
   "metadata": {
    "papermill": {
     "duration": 1.815172,
     "end_time": "2021-06-12T15:10:26.070321",
     "exception": false,
     "start_time": "2021-06-12T15:10:24.255149",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2021-07-05T09:48:51.341433Z",
     "iopub.execute_input": "2021-07-05T09:48:51.341900Z",
     "iopub.status.idle": "2021-07-05T09:48:52.532567Z",
     "shell.execute_reply.started": "2021-07-05T09:48:51.341862Z",
     "shell.execute_reply": "2021-07-05T09:48:52.531530Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/8 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a663cb11c334485abcf2ee625604dc89"
      }
     },
     "metadata": {}
    },
    {
     "name": "stdout",
     "text": "['gs://kds-55637b5723913dd2aa41ad441683c14cb5d74b82388699ddbc7a358a/train00-35000.tfrec', 'gs://kds-55637b5723913dd2aa41ad441683c14cb5d74b82388699ddbc7a358a/train01-35000.tfrec', 'gs://kds-55637b5723913dd2aa41ad441683c14cb5d74b82388699ddbc7a358a/train00-35000.tfrec', 'gs://kds-55637b5723913dd2aa41ad441683c14cb5d74b82388699ddbc7a358a/train01-35000.tfrec', 'gs://kds-55637b5723913dd2aa41ad441683c14cb5d74b82388699ddbc7a358a/train00-35000.tfrec', 'gs://kds-55637b5723913dd2aa41ad441683c14cb5d74b82388699ddbc7a358a/train01-35000.tfrec', 'gs://kds-55637b5723913dd2aa41ad441683c14cb5d74b82388699ddbc7a358a/train00-35000.tfrec', 'gs://kds-55637b5723913dd2aa41ad441683c14cb5d74b82388699ddbc7a358a/train01-35000.tfrec', 'gs://kds-55637b5723913dd2aa41ad441683c14cb5d74b82388699ddbc7a358a/train00-35000.tfrec', 'gs://kds-55637b5723913dd2aa41ad441683c14cb5d74b82388699ddbc7a358a/train01-35000.tfrec', 'gs://kds-55637b5723913dd2aa41ad441683c14cb5d74b82388699ddbc7a358a/train00-35000.tfrec', 'gs://kds-55637b5723913dd2aa41ad441683c14cb5d74b82388699ddbc7a358a/train01-35000.tfrec', 'gs://kds-55637b5723913dd2aa41ad441683c14cb5d74b82388699ddbc7a358a/train00-35000.tfrec', 'gs://kds-55637b5723913dd2aa41ad441683c14cb5d74b82388699ddbc7a358a/train01-35000.tfrec', 'gs://kds-55637b5723913dd2aa41ad441683c14cb5d74b82388699ddbc7a358a/train00-35000.tfrec', 'gs://kds-55637b5723913dd2aa41ad441683c14cb5d74b82388699ddbc7a358a/train01-35000.tfrec']\ntrain_files: 16\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Reading Tfrecords"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.020506,
     "end_time": "2021-06-12T15:10:26.31495",
     "exception": false,
     "start_time": "2021-06-12T15:10:26.294444",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "def mixup(image, label, PROBABILITY=1.0, AUG_BATCH=BATCH_SIZES[0] * REPLICAS):\n",
    "\t# input image - is a batch of images of size [n,dim,dim,3] not a single image of [dim,dim,3]\n",
    "\t# output - a batch of images with mixup applied\n",
    "\tDIM = IMG_SIZES[0]\n",
    "\n",
    "\timgs = [];\n",
    "\tlabs = []\n",
    "\tfor j in range(AUG_BATCH):\n",
    "\t\t# DO MIXUP WITH PROBABILITY DEFINED ABOVE\n",
    "\t\tP = tf.cast(tf.random.uniform([], 0, 1) <= PROBABILITY, tf.float32)\n",
    "\t\t# CHOOSE RANDOM\n",
    "\t\tk = tf.cast(tf.random.uniform([], 0, AUG_BATCH), tf.int32)\n",
    "\t\ta = tf.random.uniform([], 0, 1) * P  # this is beta dist with alpha=1.0\n",
    "\t\t# MAKE MIXUP IMAGE\n",
    "\t\timg1 = image[j,]\n",
    "\t\timg2 = image[k,]\n",
    "\t\timgs.append((1 - a) * img1 + a * img2)\n",
    "\t\t# MAKE CUTMIX LABEL\n",
    "\t\tlab1 = label[j,]\n",
    "\t\tlab2 = label[k,]\n",
    "\t\tlabs.append((1 - a) * lab1 + a * lab2)\n",
    "\n",
    "\t# RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR (maybe use Python typing instead?)\n",
    "\timage2 = tf.reshape(tf.stack(imgs), (AUG_BATCH, DIM, DIM, 3))\n",
    "\tlabel2 = tf.reshape(tf.stack(labs), (AUG_BATCH,))\n",
    "\treturn image2, label2\n",
    "\n",
    "\n",
    "def time_shift(img, shift=T_SHIFT):\n",
    "\tT = IMG_SIZES[0]\n",
    "\tP = tf.random.uniform([], 0, 1)\n",
    "\tSHIFT = tf.cast(T * P, tf.int32)\n",
    "\treturn tf.concat([img[-SHIFT:], img[:-SHIFT]], axis=0)\n",
    "\n",
    "\n",
    "def spector_shift(img, shift=S_SHIFT):\n",
    "\tT = IMG_SIZES[1]\n",
    "\tP = tf.random.uniform([], 0, 1)\n",
    "\tSHIFT = tf.cast(T * P, tf.int32)\n",
    "\treturn tf.concat([img[:, -SHIFT:], img[:, :-SHIFT]], axis=1)\n",
    "\n",
    "\n",
    "def rotate(img, angle=R_ANGLE):\n",
    "\tP = tf.random.uniform([], 0, 1)\n",
    "\tA = tf.cast(R_ANGLE * P, tf.float32)\n",
    "\treturn tfa.image.rotate(img, A)\n",
    "\n",
    "\n",
    "def img_aug_f(img):\n",
    "\timg = time_shift(img)\n",
    "\timg = spector_shift(img)\n",
    "\timg = rotate(img)\n",
    "\treturn img\n",
    "\n",
    "\n",
    "def imgs_aug_f(imgs, batch_size):\n",
    "\t_imgs = []\n",
    "\tDIM = IMG_SIZES[0]\n",
    "\tfor j in range(batch_size):\n",
    "\t\t_imgs.append(img_aug_f(imgs[j]))\n",
    "\treturn tf.reshape(tf.stack(_imgs), (batch_size, DIM, DIM, 3))\n",
    "\n",
    "\n",
    "def aug_f(imgs, labels, batch_size):\n",
    "\timgs, label = mixup(imgs, labels, MIX_UP_P, batch_size)\n",
    "\timgs = imgs_aug_f(imgs, batch_size)\n",
    "\treturn imgs, label\n",
    "\n",
    "\n",
    "def read_labeled_tfrecord(example):\n",
    "\ttfrec_format = {\n",
    "\t\t'image': tf.io.FixedLenFeature([], tf.string),\n",
    "\t\t'image_id': tf.io.FixedLenFeature([], tf.string),\n",
    "\t\t'target': tf.io.FixedLenFeature([], tf.int64)\n",
    "\t}\n",
    "\texample = tf.io.parse_single_example(example, tfrec_format)\n",
    "\treturn prepare_image(example['image']), tf.reshape(tf.cast(example['target'], tf.float32), [1])\n",
    "\n",
    "\n",
    "def read_unlabeled_tfrecord(example, return_image_id):\n",
    "\ttfrec_format = {\n",
    "\t\t'image': tf.io.FixedLenFeature([], tf.string),\n",
    "\t\t'image_id': tf.io.FixedLenFeature([], tf.string),\n",
    "\t}\n",
    "\texample = tf.io.parse_single_example(example, tfrec_format)\n",
    "\treturn prepare_image(example['image']), example['image_id'] if return_image_id else 0\n",
    "\n",
    "\n",
    "def prepare_image(img, dim=IMG_SIZES[0]):\n",
    "\timg = tf.image.resize(tf.image.decode_png(img, channels=3), size=(dim, dim))\n",
    "\timg = tf.cast(img, tf.float32) / 255.0\n",
    "\timg = tf.reshape(img, [dim, dim, 3])\n",
    "\n",
    "\treturn img\n",
    "\n",
    "\n",
    "def count_data_items(fileids):\n",
    "\tn = [int(re.compile(r\"-([0-9]*)\\.\").search(fileid).group(1))\n",
    "\t     for fileid in fileids]\n",
    "\treturn np.sum(n)"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.046323,
     "end_time": "2021-06-12T15:10:26.380685",
     "exception": false,
     "start_time": "2021-06-12T15:10:26.334362",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset Creation"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.01899,
     "end_time": "2021-06-12T15:10:26.419124",
     "exception": false,
     "start_time": "2021-06-12T15:10:26.400134",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def get_dataset(files, shuffle=False, repeat=False,\n",
    "                labeled=True, return_image_ids=True, batch_size=16, dim=IMG_SIZES[0], aug=False):\n",
    "\tds = tf.data.TFRecordDataset(files, num_parallel_reads=AUTO)\n",
    "\tds = ds.cache()\n",
    "\n",
    "\tif repeat:\n",
    "\t\tds = ds.repeat()\n",
    "\n",
    "\tif shuffle:\n",
    "\t\tds = ds.shuffle(1024 * 2)\n",
    "\t\topt = tf.data.Options()\n",
    "\t\topt.experimental_deterministic = False\n",
    "\t\tds = ds.with_options(opt)\n",
    "\n",
    "\tif labeled:\n",
    "\t\tds = ds.map(read_labeled_tfrecord, num_parallel_calls=AUTO)\n",
    "\telse:\n",
    "\t\tds = ds.map(lambda example: read_unlabeled_tfrecord(example, return_image_ids),\n",
    "\t\t            num_parallel_calls=AUTO)\n",
    "\n",
    "\tds = ds.batch(batch_size * REPLICAS)\n",
    "\tif aug:\n",
    "\t\tds = ds.map(lambda x, y: aug_f(x, y, batch_size * REPLICAS), num_parallel_calls=AUTO)\n",
    "\tds = ds.prefetch(AUTO)\n",
    "\treturn ds"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Build Model"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.019046,
     "end_time": "2021-06-12T15:10:26.458368",
     "exception": false,
     "start_time": "2021-06-12T15:10:26.439322",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "source": [
    "EFNS = [efn.EfficientNetB0, efn.EfficientNetB1, efn.EfficientNetB2, efn.EfficientNetB3,\n",
    "        efn.EfficientNetB4, efn.EfficientNetB5, efn.EfficientNetB6, efn.EfficientNetB7]\n",
    "\n",
    "\n",
    "def build_model(size, ef=0, count=820):\n",
    "\tinp = tf.keras.layers.Input(shape=(size, size, 3))\n",
    "\tbase = EFNS[ef](input_shape=(size, size, 3), weights='imagenet', include_top=False)\n",
    "\n",
    "\tx = base(inp)\n",
    "\n",
    "\tx = tf.keras.layers.GlobalAvgPool2D()(x)\n",
    "\n",
    "\tx = tf.keras.layers.Dropout(0.5)(x)\n",
    "\tx = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\tmodel = tf.keras.Model(inputs=inp, outputs=x)\n",
    "\tlr_decayed_fn = tf.keras.experimental.CosineDecay(\n",
    "\t\t1e-3,\n",
    "\t\tcount,\n",
    "\t)\n",
    "\n",
    "\topt = tfa.optimizers.AdamW(lr_decayed_fn, learning_rate=1e-4)\n",
    "\tloss = tf.keras.losses.BinaryCrossentropy()\n",
    "\tmodel.compile(optimizer=opt, loss=loss, metrics=['AUC'])\n",
    "\treturn model"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.038147,
     "end_time": "2021-06-12T15:10:26.519338",
     "exception": false,
     "start_time": "2021-06-12T15:10:26.481191",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.019514,
     "end_time": "2021-06-12T15:10:26.55885",
     "exception": false,
     "start_time": "2021-06-12T15:10:26.539336",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def vis_lr_callback(batch_size=8):\n",
    "\tlr_start = 1e-4\n",
    "\tlr_max = 0.000015 * REPLICAS * batch_size\n",
    "\tlr_min = 1e-5\n",
    "\tlr_ramp_ep = 4\n",
    "\tlr_sus_ep = 0\n",
    "\tlr_decay = 0.7\n",
    "\n",
    "\tdef lrfn(epoch):\n",
    "\t\tif epoch < lr_ramp_ep:\n",
    "\t\t\tlr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n",
    "\n",
    "\t\telif epoch < lr_ramp_ep + lr_sus_ep:\n",
    "\t\t\tlr = lr_max\n",
    "\n",
    "\t\telse:\n",
    "\t\t\tlr = (lr_max - lr_min) * lr_decay ** (epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n",
    "\n",
    "\t\treturn lr\n",
    "\n",
    "\tplt.figure(figsize=(10, 7))\n",
    "\tplt.plot([lrfn(i) for i in range(EPOCHS[0])])\n",
    "\tplt.show()"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def get_lr_callback(batch_size=8):\n",
    "\tlr_start = 1e-4\n",
    "\tlr_max = 0.000015 * REPLICAS * batch_size\n",
    "\tlr_min = 1e-7\n",
    "\tlr_ramp_ep = 4\n",
    "\tlr_sus_ep = 0\n",
    "\tlr_decay = 0.7\n",
    "\n",
    "\tdef lrfn(epoch):\n",
    "\t\tif epoch < lr_ramp_ep:\n",
    "\t\t\tlr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n",
    "\n",
    "\t\telif epoch < lr_ramp_ep + lr_sus_ep:\n",
    "\t\t\tlr = lr_max\n",
    "\n",
    "\t\telse:\n",
    "\t\t\tlr = (lr_max - lr_min) * lr_decay ** (epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n",
    "\n",
    "\t\treturn lr\n",
    "\n",
    "\tlr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=False)\n",
    "\treturn lr_callback"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.029922,
     "end_time": "2021-06-12T15:10:26.608518",
     "exception": false,
     "start_time": "2021-06-12T15:10:26.578596",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "vis_lr_callback(BATCH_SIZES[0])"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "skf = KFold(n_splits=KFOLDS, shuffle=True, random_state=RANDOM_SEED)\n",
    "oof_pred = [];\n",
    "oof_tar = [];\n",
    "oof_val = [];\n",
    "oof_f1 = [];\n",
    "oof_ids = [];\n",
    "oof_folds = []\n",
    "\n",
    "files_train_g = np.array(files_train_g)\n",
    "\n",
    "for fold, (idxT, idxV) in enumerate(skf.split(files_train_g)):\n",
    "\t# CREATE TRAIN AND VALIDATION SUBSETS\n",
    "\tfiles_train = files_train_g[idxT]\n",
    "\tnp.random.shuffle(files_train);\n",
    "\tfiles_valid = files_train_g[idxV]\n",
    "\n",
    "\tprint('#' * 25);\n",
    "\tprint('#### FOLD', fold + 1)\n",
    "\tprint('#### Image Size: %i | model: %s | batch_size %i' %\n",
    "\t      (IMG_SIZES[fold], EFNS[EFF_NETS[fold]].__name__, BATCH_SIZES[fold] * REPLICAS))\n",
    "\ttrain_images = count_data_items(files_train)\n",
    "\tval_images = count_data_items(files_valid)\n",
    "\tprint('#### Training: %i | Validation: %i' % (train_images, val_images))\n",
    "\n",
    "\t# BUILD MODEL\n",
    "\tK.clear_session()\n",
    "\twith strategy.scope():\n",
    "\t\tmodel = build_model(IMG_SIZES[fold], ef=EFF_NETS[fold],\n",
    "\t\t                    count=count_data_items(files_train) / BATCH_SIZES[fold] // REPLICAS // 4)\n",
    "\tprint('#' * 25)\n",
    "\t# SAVE BEST MODEL EACH FOLD\n",
    "\tsv = tf.keras.callbacks.ModelCheckpoint(\n",
    "\t\t'fold-%i.h5' % fold, monitor='val_auc', verbose=0, save_best_only=True,\n",
    "\t\tsave_weights_only=True, mode='max', save_freq='epoch')\n",
    "\n",
    "\t# TRAIN\n",
    "\tprint('Training...')\n",
    "\thistory = model.fit(\n",
    "\t\tget_dataset(files_train, shuffle=True, repeat=True,\n",
    "\t\t            dim=IMG_SIZES[fold], batch_size=BATCH_SIZES[fold], aug=AUG),\n",
    "\t\tepochs=EPOCHS[fold],\n",
    "\t\tcallbacks=[sv, get_lr_callback(BATCH_SIZES[fold])],\n",
    "\t\tsteps_per_epoch=count_data_items(files_train) / BATCH_SIZES[fold] // REPLICAS // 4,\n",
    "\t\tvalidation_data=get_dataset(files_valid, shuffle=False,\n",
    "\t\t                            repeat=False, dim=IMG_SIZES[fold]),\n",
    "\t\tverbose=1\n",
    "\t)\n",
    "\n",
    "\t# Loading best model for inference\n",
    "\tprint('Loading best model...')\n",
    "\tmodel.load_weights('fold-%i.h5' % fold)\n",
    "\n",
    "\tds_valid = get_dataset(files_valid, labeled=False, return_image_ids=False,\n",
    "\t                       repeat=True, shuffle=False, dim=IMG_SIZES[fold], batch_size=BATCH_SIZES[fold] * 2)\n",
    "\tct_valid = count_data_items(files_valid);\n",
    "\tSTEPS = ct_valid / BATCH_SIZES[fold] / 2 / REPLICAS\n",
    "\tpred = model.predict(ds_valid, steps=STEPS, verbose=0)[:ct_valid, ]\n",
    "\toof_pred.append(np.mean(pred.reshape((ct_valid, 1), order='F'), axis=1))\n",
    "\n",
    "\t# GET OOF TARGETS AND idS\n",
    "\tds_valid = get_dataset(files_valid, repeat=False, dim=IMG_SIZES[fold],\n",
    "\t                       labeled=True, return_image_ids=True)\n",
    "\toof_tar.append(np.array([target.numpy() for img, target in iter(ds_valid.unbatch())]))\n",
    "\n",
    "\t# PLOT TRAINING\n",
    "\tif DISPLAY_PLOT:\n",
    "\t\tplt.figure(figsize=(8, 6))\n",
    "\t\tsns.distplot(oof_pred[-1])\n",
    "\t\tplt.show()\n",
    "\n",
    "\t\tplt.figure(figsize=(15, 5))\n",
    "\t\tplt.plot(np.arange(len(history.history['auc'])), history.history['auc'], '-o', label='Train auc',\n",
    "\t\t         color='#ff7f0e')\n",
    "\t\tplt.plot(np.arange(len(history.history['auc'])), history.history['val_auc'], '-o', label='Val auc',\n",
    "\t\t         color='#1f77b4')\n",
    "\t\tx = np.argmax(history.history['val_auc']);\n",
    "\t\ty = np.max(history.history['val_auc'])\n",
    "\t\txdist = plt.xlim()[1] - plt.xlim()[0];\n",
    "\t\tydist = plt.ylim()[1] - plt.ylim()[0]\n",
    "\t\tplt.scatter(x, y, s=200, color='#1f77b4');\n",
    "\t\tplt.text(x - 0.03 * xdist, y - 0.13 * ydist, 'max auc\\n%.2f' % y, size=14)\n",
    "\t\tplt.ylabel('auc', size=14);\n",
    "\t\tplt.xlabel('Epoch', size=14)\n",
    "\t\tplt.legend(loc=2)\n",
    "\t\tplt2 = plt.gca().twinx()\n",
    "\t\tplt2.plot(np.arange(len(history.history['auc'])), history.history['loss'], '-o', label='Train Loss',\n",
    "\t\t          color='#2ca02c')\n",
    "\t\tplt2.plot(np.arange(len(history.history['auc'])), history.history['val_loss'], '-o', label='Val Loss',\n",
    "\t\t          color='#d62728')\n",
    "\t\tx = np.argmin(history.history['val_loss']);\n",
    "\t\ty = np.min(history.history['val_loss'])\n",
    "\t\tydist = plt.ylim()[1] - plt.ylim()[0]\n",
    "\t\tplt.scatter(x, y, s=200, color='#d62728');\n",
    "\t\tplt.text(x - 0.03 * xdist, y + 0.05 * ydist, 'min loss', size=14)\n",
    "\t\tplt.ylabel('Loss', size=14)\n",
    "\t\tplt.title('FOLD %i - Image Size %i, %s' %\n",
    "\t\t          (fold + 1, IMG_SIZES[fold], EFNS[EFF_NETS[fold]].__name__), size=18)\n",
    "\t\tplt.legend(loc=3)\n",
    "\t\tplt.savefig(f'fig{fold}.png')\n",
    "\t\tplt.show()"
   ],
   "metadata": {
    "papermill": {
     "duration": 21.234649,
     "end_time": "2021-06-12T18:39:46.151391",
     "exception": false,
     "start_time": "2021-06-12T18:39:24.916742",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "oof = np.concatenate(oof_pred);\n",
    "true = np.concatenate(oof_tar);\n",
    "auc = roc_auc_score(true, oof)\n",
    "print('Overall OOF AUC= %.3f' % auc)"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Datasets\n* [Q-Transform TFRecords](https://www.kaggle.com/miklgr500/q-transform-tfrecords)\n    * [CQT G2Net V2 [0 - 1]](https://www.kaggle.com/miklgr500/cqt-g2net-v2-0-1)\n    * [CQT G2Net V2 [2 - 3]](https://www.kaggle.com/miklgr500/cqt-g2net-v2-2-3)\n    * [CQT G2Net V2 [4 - 5]](https://www.kaggle.com/miklgr500/cqt-g2net-v2-4-5)\n    * [CQT G2Net V2 [6 - 7]](https://www.kaggle.com/miklgr500/cqt-g2net-v2-6-7)\n    * [CQT G2Net V2 [8 - 9]](https://www.kaggle.com/miklgr500/cqt-g2net-v2-8-9)\n    * [CQT G2Net V2 [10 - 11]](https://www.kaggle.com/miklgr500/cqt-g2net-v2-10-11)\n    * [CQT G2Net V2 [12 - 13]](https://www.kaggle.com/miklgr500/cqt-g2net-v2-12-13)\n    * [CQT G2Net V2 [14 - 15]](https://www.kaggle.com/miklgr500/cqt-g2net-v2-14-15)",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "# Next steps\n* Generate Test Sets\n* Create Inference Notebook\n* Add augmentation\n* Add TTA Inference",
   "metadata": {}
  }
 ]
}