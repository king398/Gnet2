{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q efficientnet","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"papermill":{"duration":9.673051,"end_time":"2021-06-12T15:10:08.223254","exception":false,"start_time":"2021-06-12T15:09:58.550203","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-05T09:47:17.269801Z","iopub.execute_input":"2021-07-05T09:47:17.270290Z","iopub.status.idle":"2021-07-05T09:47:27.151576Z","shell.execute_reply.started":"2021-07-05T09:47:17.270197Z","shell.execute_reply":"2021-07-05T09:47:27.150153Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Asthetics\nimport warnings\nimport sklearn.exceptions\nwarnings.filterwarnings('ignore', category=DeprecationWarning)\nwarnings.filterwarnings('ignore', category=FutureWarning)\nwarnings.filterwarnings(\"ignore\", category=sklearn.exceptions.UndefinedMetricWarning)\n\n# General\nfrom kaggle_datasets import KaggleDatasets\nfrom glob import glob\nimport pandas as pd\nimport numpy as np\nimport os\nimport time\nimport cv2\nimport random\nimport shutil\nimport math\nimport re\npd.set_option('display.max_columns', None)\n\n# Visualizations\nfrom PIL import Image\nfrom plotly.subplots import make_subplots\nfrom plotly.offline import iplot\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\nimport plotly.express as px\n%matplotlib inline\nsns.set(style=\"whitegrid\")\n\n# Machine Learning\n# Pre Procesing\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\n# Models\nfrom sklearn.model_selection import train_test_split, KFold\n# Deep Learning\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nimport efficientnet.tfkeras as efn\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import EfficientNetB4\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, BatchNormalization, GlobalAveragePooling2D\nfrom tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import CategoricalCrossentropy\nimport tensorflow_addons as tfa\nfrom tensorflow_addons.metrics import F1Score, FBetaScore\nfrom tensorflow_addons.callbacks import TQDMProgressBar\nfrom tensorflow.keras.utils import plot_model\n\n#Metrics\nfrom sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n\nprint('TF',tf.__version__)\n\n# Random Seed Fixing\nRANDOM_SEED = 42\n\ndef seed_everything(seed=RANDOM_SEED):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    tf.random.set_seed(seed)\n\nseed_everything()","metadata":{"papermill":{"duration":10.406747,"end_time":"2021-06-12T15:10:18.648284","exception":false,"start_time":"2021-06-12T15:10:08.241537","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-05T09:47:27.153600Z","iopub.execute_input":"2021-07-05T09:47:27.153954Z","iopub.status.idle":"2021-07-05T09:47:37.597021Z","shell.execute_reply.started":"2021-07-05T09:47:27.153910Z","shell.execute_reply":"2021-07-05T09:47:37.596197Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"TF 2.4.1\n","output_type":"stream"}]},{"cell_type":"code","source":"# From https://www.kaggle.com/xhlulu/ranzcr-efficientnet-tpu-training\ndef auto_select_accelerator():\n    TPU_DETECTED = False\n    try:\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n        tf.config.experimental_connect_to_cluster(tpu)\n        tf.tpu.experimental.initialize_tpu_system(tpu)\n        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n        print(\"Running on TPU:\", tpu.master())\n        TPU_DETECTED =True\n    except ValueError:\n        strategy = tf.distribute.get_strategy()\n    print(f\"Running on {strategy.num_replicas_in_sync} replicas\")\n    \n    return strategy, TPU_DETECTED","metadata":{"papermill":{"duration":0.02909,"end_time":"2021-06-12T15:10:18.696808","exception":false,"start_time":"2021-06-12T15:10:18.667718","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-05T09:47:37.599013Z","iopub.execute_input":"2021-07-05T09:47:37.599595Z","iopub.status.idle":"2021-07-05T09:47:37.606065Z","shell.execute_reply.started":"2021-07-05T09:47:37.599559Z","shell.execute_reply":"2021-07-05T09:47:37.605065Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# CFG","metadata":{"papermill":{"duration":0.017986,"end_time":"2021-06-12T15:10:18.733021","exception":false,"start_time":"2021-06-12T15:10:18.715035","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Model Params\nKFOLDS = 4\nIMG_SIZES = [256]*KFOLDS\nBATCH_SIZES = [64]*KFOLDS\nEPOCHS = [30]*KFOLDS\nEFF_NETS = [1]*KFOLDS # WHICH EFFICIENTNET B? TO USE\n\nAUG = True\nMIX_UP_P = 0.1\nS_SHIFT = 0.0\nT_SHIFT = 0.0\nR_ANGLE = 0 / 180 * np.pi\n\n# Model Eval Params\nDISPLAY_PLOT = True\n\n# Inference Params\nWGTS = [1/KFOLDS]*KFOLDS","metadata":{"papermill":{"duration":0.030113,"end_time":"2021-06-12T15:10:18.781524","exception":false,"start_time":"2021-06-12T15:10:18.751411","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-05T09:47:37.607940Z","iopub.execute_input":"2021-07-05T09:47:37.608544Z","iopub.status.idle":"2021-07-05T09:47:37.622181Z","shell.execute_reply.started":"2021-07-05T09:47:37.608460Z","shell.execute_reply":"2021-07-05T09:47:37.620569Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"strategy, TPU_DETECTED = auto_select_accelerator()\nAUTO = tf.data.experimental.AUTOTUNE\nREPLICAS = strategy.num_replicas_in_sync","metadata":{"papermill":{"duration":5.397929,"end_time":"2021-06-12T15:10:24.197997","exception":false,"start_time":"2021-06-12T15:10:18.800068","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-05T09:47:37.624012Z","iopub.execute_input":"2021-07-05T09:47:37.624633Z","iopub.status.idle":"2021-07-05T09:47:37.645355Z","shell.execute_reply.started":"2021-07-05T09:47:37.624586Z","shell.execute_reply":"2021-07-05T09:47:37.643654Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Running on 1 replicas\n","output_type":"stream"}]},{"cell_type":"code","source":"from tqdm.notebook import tqdm\n\nfiles_train_g = []\nfor i,k in tqdm([(0, 1), (2, 3), (4,5), (6, 7), (8, 9) ,(10,11), (12, 13), (14, 15)]):\n    GCS_PATH = \"gs://kds-55637b5723913dd2aa41ad441683c14cb5d74b82388699ddbc7a358a\"\n    files_train_g.extend(np.sort(np.array(tf.io.gfile.glob(GCS_PATH + '/train*.tfrec'))).tolist())\nnum_train_files = len(files_train_g)\nprint(files_train_g)\nprint('train_files:',num_train_files)","metadata":{"papermill":{"duration":1.815172,"end_time":"2021-06-12T15:10:26.070321","exception":false,"start_time":"2021-06-12T15:10:24.255149","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-05T09:48:51.341433Z","iopub.execute_input":"2021-07-05T09:48:51.341900Z","iopub.status.idle":"2021-07-05T09:48:52.532567Z","shell.execute_reply.started":"2021-07-05T09:48:51.341862Z","shell.execute_reply":"2021-07-05T09:48:52.531530Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/8 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a663cb11c334485abcf2ee625604dc89"}},"metadata":{}},{"name":"stdout","text":"['gs://kds-55637b5723913dd2aa41ad441683c14cb5d74b82388699ddbc7a358a/train00-35000.tfrec', 'gs://kds-55637b5723913dd2aa41ad441683c14cb5d74b82388699ddbc7a358a/train01-35000.tfrec', 'gs://kds-55637b5723913dd2aa41ad441683c14cb5d74b82388699ddbc7a358a/train00-35000.tfrec', 'gs://kds-55637b5723913dd2aa41ad441683c14cb5d74b82388699ddbc7a358a/train01-35000.tfrec', 'gs://kds-55637b5723913dd2aa41ad441683c14cb5d74b82388699ddbc7a358a/train00-35000.tfrec', 'gs://kds-55637b5723913dd2aa41ad441683c14cb5d74b82388699ddbc7a358a/train01-35000.tfrec', 'gs://kds-55637b5723913dd2aa41ad441683c14cb5d74b82388699ddbc7a358a/train00-35000.tfrec', 'gs://kds-55637b5723913dd2aa41ad441683c14cb5d74b82388699ddbc7a358a/train01-35000.tfrec', 'gs://kds-55637b5723913dd2aa41ad441683c14cb5d74b82388699ddbc7a358a/train00-35000.tfrec', 'gs://kds-55637b5723913dd2aa41ad441683c14cb5d74b82388699ddbc7a358a/train01-35000.tfrec', 'gs://kds-55637b5723913dd2aa41ad441683c14cb5d74b82388699ddbc7a358a/train00-35000.tfrec', 'gs://kds-55637b5723913dd2aa41ad441683c14cb5d74b82388699ddbc7a358a/train01-35000.tfrec', 'gs://kds-55637b5723913dd2aa41ad441683c14cb5d74b82388699ddbc7a358a/train00-35000.tfrec', 'gs://kds-55637b5723913dd2aa41ad441683c14cb5d74b82388699ddbc7a358a/train01-35000.tfrec', 'gs://kds-55637b5723913dd2aa41ad441683c14cb5d74b82388699ddbc7a358a/train00-35000.tfrec', 'gs://kds-55637b5723913dd2aa41ad441683c14cb5d74b82388699ddbc7a358a/train01-35000.tfrec']\ntrain_files: 16\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Reading Tfrecords","metadata":{"papermill":{"duration":0.020506,"end_time":"2021-06-12T15:10:26.31495","exception":false,"start_time":"2021-06-12T15:10:26.294444","status":"completed"},"tags":[]}},{"cell_type":"code","source":"\ndef mixup(image, label, PROBABILITY = 1.0, AUG_BATCH=BATCH_SIZES[0] * REPLICAS):\n    # input image - is a batch of images of size [n,dim,dim,3] not a single image of [dim,dim,3]\n    # output - a batch of images with mixup applied\n    DIM = IMG_SIZES[0]\n    \n    imgs = []; labs = []\n    for j in range(AUG_BATCH):\n        # DO MIXUP WITH PROBABILITY DEFINED ABOVE\n        P = tf.cast( tf.random.uniform([],0,1)<=PROBABILITY, tf.float32)\n        # CHOOSE RANDOM\n        k = tf.cast( tf.random.uniform([],0,AUG_BATCH),tf.int32)\n        a = tf.random.uniform([],0,1)*P # this is beta dist with alpha=1.0\n        # MAKE MIXUP IMAGE\n        img1 = image[j,]\n        img2 = image[k,]\n        imgs.append((1-a)*img1 + a*img2)\n        # MAKE CUTMIX LABEL\n        lab1 = label[j,]\n        lab2 = label[k,]\n        labs.append((1-a)*lab1 + a*lab2)\n            \n    # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR (maybe use Python typing instead?)\n    image2 = tf.reshape(tf.stack(imgs),(AUG_BATCH,DIM,DIM,3))\n    label2 = tf.reshape(tf.stack(labs),(AUG_BATCH,))\n    return image2,label2\n\ndef time_shift(img, shift=T_SHIFT):\n    T = IMG_SIZES[0]\n    P = tf.random.uniform([],0,1)\n    SHIFT = tf.cast(T * P, tf.int32)\n    return tf.concat([img[-SHIFT:], img[:-SHIFT]], axis=0)\n\n\ndef spector_shift(img, shift=S_SHIFT):\n    T = IMG_SIZES[1]\n    P = tf.random.uniform([],0,1)\n    SHIFT = tf.cast(T * P, tf.int32)\n    return tf.concat([img[:, -SHIFT:], img[:, :-SHIFT]], axis=1)\n\ndef rotate(img, angle=R_ANGLE):\n    P = tf.random.uniform([],0,1)\n    A = tf.cast(R_ANGLE * P, tf.float32)\n    return tfa.image.rotate(img, A)\n\n    \ndef img_aug_f(img):\n    img = time_shift(img)\n    img = spector_shift(img)\n    img = rotate(img)\n    return img\n\ndef imgs_aug_f(imgs, batch_size):\n    _imgs = []\n    DIM = IMG_SIZES[0]\n    for j in range(batch_size):\n        _imgs.append(img_aug_f(imgs[j]))\n    return tf.reshape(tf.stack(_imgs),(batch_size,DIM,DIM,3))\n\n\ndef aug_f(imgs, labels, batch_size):\n    imgs, label = mixup(imgs, labels, MIX_UP_P, batch_size)\n    imgs = imgs_aug_f(imgs, batch_size)\n    return imgs, label\n\ndef read_labeled_tfrecord(example):\n    tfrec_format = {\n        'image'                        : tf.io.FixedLenFeature([], tf.string),\n        'image_id'                     : tf.io.FixedLenFeature([], tf.string),\n        'target'                       : tf.io.FixedLenFeature([], tf.int64)\n    }           \n    example = tf.io.parse_single_example(example, tfrec_format)\n    return prepare_image(example['image']), tf.reshape(tf.cast(example['target'], tf.float32), [1])\n\n\ndef read_unlabeled_tfrecord(example, return_image_id):\n    tfrec_format = {\n        'image'                        : tf.io.FixedLenFeature([], tf.string),\n        'image_id'                     : tf.io.FixedLenFeature([], tf.string),\n    }\n    example = tf.io.parse_single_example(example, tfrec_format)\n    return prepare_image(example['image']), example['image_id'] if return_image_id else 0\n\n \ndef prepare_image(img, dim=IMG_SIZES[0]):    \n    img = tf.image.resize(tf.image.decode_png(img, channels=3), size=(dim, dim))\n    img = tf.cast(img, tf.float32) / 255.0\n    img = tf.reshape(img, [dim,dim, 3])\n            \n    return img\n\ndef count_data_items(fileids):\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(fileid).group(1)) \n         for fileid in fileids]\n    return np.sum(n)","metadata":{"papermill":{"duration":0.046323,"end_time":"2021-06-12T15:10:26.380685","exception":false,"start_time":"2021-06-12T15:10:26.334362","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset Creation","metadata":{"papermill":{"duration":0.01899,"end_time":"2021-06-12T15:10:26.419124","exception":false,"start_time":"2021-06-12T15:10:26.400134","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def get_dataset(files, shuffle = False, repeat = False, \n                labeled=True, return_image_ids=True, batch_size=16, dim=IMG_SIZES[0], aug=False):\n    \n    ds = tf.data.TFRecordDataset(files, num_parallel_reads=AUTO)\n    ds = ds.cache()\n    \n    if repeat:\n        ds = ds.repeat()\n    \n    if shuffle: \n        ds = ds.shuffle(1024*2)\n        opt = tf.data.Options()\n        opt.experimental_deterministic = False\n        ds = ds.with_options(opt)\n        \n    if labeled: \n        ds = ds.map(read_labeled_tfrecord, num_parallel_calls=AUTO)\n    else:\n        ds = ds.map(lambda example: read_unlabeled_tfrecord(example, return_image_ids), \n                    num_parallel_calls=AUTO)      \n    \n    ds = ds.batch(batch_size * REPLICAS)\n    if aug:\n        ds = ds.map(lambda x, y: aug_f(x, y, batch_size * REPLICAS), num_parallel_calls=AUTO)\n    ds = ds.prefetch(AUTO)\n    return ds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Build Model","metadata":{"papermill":{"duration":0.019046,"end_time":"2021-06-12T15:10:26.458368","exception":false,"start_time":"2021-06-12T15:10:26.439322","status":"completed"},"tags":[]}},{"cell_type":"code","source":"EFNS = [efn.EfficientNetB0, efn.EfficientNetB1, efn.EfficientNetB2, efn.EfficientNetB3, \n        efn.EfficientNetB4, efn.EfficientNetB5, efn.EfficientNetB6, efn.EfficientNetB7]\n\ndef build_model(size, ef=0, count=820):\n    inp = tf.keras.layers.Input(shape=(size, size,3))\n    base = EFNS[ef](input_shape=(size,size,3),weights='imagenet',include_top=False)\n    \n    x = base(inp)\n    \n    x = tf.keras.layers.GlobalAvgPool2D()(x)\n    \n    x = tf.keras.layers.Dropout(0.5)(x)\n    x = tf.keras.layers.Dense(1,activation='sigmoid')(x)\n    model = tf.keras.Model(inputs=inp, outputs=x)\n    lr_decayed_fn = tf.keras.experimental.CosineDecay(\n                              1e-3,\n                              count,\n    )\n\n    opt = tfa.optimizers.AdamW(lr_decayed_fn, learning_rate=1e-4)\n    loss = tf.keras.losses.BinaryCrossentropy() \n    model.compile(optimizer=opt,loss=loss,metrics=['AUC'])\n    return model","metadata":{"papermill":{"duration":0.038147,"end_time":"2021-06-12T15:10:26.519338","exception":false,"start_time":"2021-06-12T15:10:26.481191","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{"papermill":{"duration":0.019514,"end_time":"2021-06-12T15:10:26.55885","exception":false,"start_time":"2021-06-12T15:10:26.539336","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def vis_lr_callback(batch_size=8):\n    lr_start   = 1e-4\n    lr_max     = 0.000015 * REPLICAS * batch_size\n    lr_min     = 1e-5\n    lr_ramp_ep = 4\n    lr_sus_ep  = 0\n    lr_decay   = 0.7\n   \n    def lrfn(epoch):\n        if epoch < lr_ramp_ep:\n            lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n            \n        elif epoch < lr_ramp_ep + lr_sus_ep:\n            lr = lr_max\n            \n        else:\n            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n            \n        return lr\n    plt.figure(figsize=(10, 7))\n    plt.plot([lrfn(i) for i in range(EPOCHS[0])])\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_lr_callback(batch_size=8):\n    lr_start   = 1e-4\n    lr_max     = 0.000015 * REPLICAS * batch_size\n    lr_min     = 1e-7\n    lr_ramp_ep = 4\n    lr_sus_ep  = 0\n    lr_decay   = 0.7\n   \n    def lrfn(epoch):\n        if epoch < lr_ramp_ep:\n            lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n            \n        elif epoch < lr_ramp_ep + lr_sus_ep:\n            lr = lr_max\n            \n        else:\n            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n            \n        return lr\n\n    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=False)\n    return lr_callback","metadata":{"papermill":{"duration":0.029922,"end_time":"2021-06-12T15:10:26.608518","exception":false,"start_time":"2021-06-12T15:10:26.578596","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vis_lr_callback(BATCH_SIZES[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"skf = KFold(n_splits=KFOLDS,shuffle=True,random_state=RANDOM_SEED)\noof_pred = []; oof_tar = []; oof_val = []; oof_f1 = []; oof_ids = []; oof_folds = [] \n\nfiles_train_g = np.array(files_train_g)\n\nfor fold,(idxT,idxV) in enumerate(skf.split(files_train_g)):\n    # CREATE TRAIN AND VALIDATION SUBSETS\n    files_train = files_train_g[idxT]\n    np.random.shuffle(files_train);\n    files_valid = files_train_g[idxV]\n    \n    print('#'*25); print('#### FOLD',fold+1)\n    print('#### Image Size: %i | model: %s | batch_size %i'%\n          (IMG_SIZES[fold],EFNS[EFF_NETS[fold]].__name__,BATCH_SIZES[fold]*REPLICAS))\n    train_images = count_data_items(files_train)\n    val_images   = count_data_items(files_valid)\n    print('#### Training: %i | Validation: %i'%(train_images, val_images))\n    \n    # BUILD MODEL\n    K.clear_session()\n    with strategy.scope():\n        model = build_model(IMG_SIZES[fold], ef=EFF_NETS[fold], \n                            count=count_data_items(files_train)/BATCH_SIZES[fold]//REPLICAS//4)\n    print('#'*25)   \n    # SAVE BEST MODEL EACH FOLD\n    sv = tf.keras.callbacks.ModelCheckpoint(\n        'fold-%i.h5'%fold, monitor='val_auc', verbose=0, save_best_only=True,\n        save_weights_only=True, mode='max', save_freq='epoch')\n   \n    # TRAIN\n    print('Training...')\n    history = model.fit(\n        get_dataset(files_train, shuffle=True, repeat=True,\n                dim=IMG_SIZES[fold], batch_size = BATCH_SIZES[fold], aug=AUG), \n        epochs=EPOCHS[fold], \n        callbacks = [sv, get_lr_callback(BATCH_SIZES[fold])], \n        steps_per_epoch=count_data_items(files_train)/BATCH_SIZES[fold]//REPLICAS//4,\n        validation_data=get_dataset(files_valid, shuffle=False,\n                repeat=False,dim=IMG_SIZES[fold]),\n        verbose=1\n    )\n    \n    # Loading best model for inference\n    print('Loading best model...')\n    model.load_weights('fold-%i.h5'%fold)  \n    \n    ds_valid = get_dataset(files_valid,labeled=False,return_image_ids=False,\n            repeat=True,shuffle=False,dim=IMG_SIZES[fold],batch_size=BATCH_SIZES[fold]*2)\n    ct_valid = count_data_items(files_valid); STEPS = ct_valid/BATCH_SIZES[fold]/2/REPLICAS\n    pred = model.predict(ds_valid,steps=STEPS,verbose=0)[:ct_valid,] \n    oof_pred.append( np.mean(pred.reshape((ct_valid,1),order='F'),axis=1) )                 \n    \n    # GET OOF TARGETS AND idS\n    ds_valid = get_dataset(files_valid, repeat=False, dim=IMG_SIZES[fold],\n            labeled=True, return_image_ids=True)\n    oof_tar.append( np.array([target.numpy() for img, target in iter(ds_valid.unbatch())]) )\n    \n    # PLOT TRAINING\n    if DISPLAY_PLOT:\n        plt.figure(figsize=(8, 6))\n        sns.distplot(oof_pred[-1])\n        plt.show()\n        \n        plt.figure(figsize=(15,5))\n        plt.plot(np.arange(len(history.history['auc'])),history.history['auc'],'-o',label='Train auc',color='#ff7f0e')\n        plt.plot(np.arange(len(history.history['auc'])),history.history['val_auc'],'-o',label='Val auc',color='#1f77b4')\n        x = np.argmax( history.history['val_auc'] ); y = np.max( history.history['val_auc'] )\n        xdist = plt.xlim()[1] - plt.xlim()[0]; ydist = plt.ylim()[1] - plt.ylim()[0]\n        plt.scatter(x,y,s=200,color='#1f77b4'); plt.text(x-0.03*xdist,y-0.13*ydist,'max auc\\n%.2f'%y,size=14)\n        plt.ylabel('auc',size=14); plt.xlabel('Epoch',size=14)\n        plt.legend(loc=2)\n        plt2 = plt.gca().twinx()\n        plt2.plot(np.arange(len(history.history['auc'])),history.history['loss'],'-o',label='Train Loss',color='#2ca02c')\n        plt2.plot(np.arange(len(history.history['auc'])),history.history['val_loss'],'-o',label='Val Loss',color='#d62728')\n        x = np.argmin( history.history['val_loss'] ); y = np.min( history.history['val_loss'] )\n        ydist = plt.ylim()[1] - plt.ylim()[0]\n        plt.scatter(x,y,s=200,color='#d62728'); plt.text(x-0.03*xdist,y+0.05*ydist,'min loss',size=14)\n        plt.ylabel('Loss',size=14)\n        plt.title('FOLD %i - Image Size %i, %s'%\n                (fold+1,IMG_SIZES[fold],EFNS[EFF_NETS[fold]].__name__),size=18)\n        plt.legend(loc=3)\n        plt.savefig(f'fig{fold}.png')\n        plt.show()","metadata":{"papermill":{"duration":21.234649,"end_time":"2021-06-12T18:39:46.151391","exception":false,"start_time":"2021-06-12T18:39:24.916742","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oof = np.concatenate(oof_pred); true = np.concatenate(oof_tar);\nauc = roc_auc_score(true,oof)\nprint('Overall OOF AUC= %.3f'%auc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Datasets\n* [Q-Transform TFRecords](https://www.kaggle.com/miklgr500/q-transform-tfrecords)\n    * [CQT G2Net V2 [0 - 1]](https://www.kaggle.com/miklgr500/cqt-g2net-v2-0-1)\n    * [CQT G2Net V2 [2 - 3]](https://www.kaggle.com/miklgr500/cqt-g2net-v2-2-3)\n    * [CQT G2Net V2 [4 - 5]](https://www.kaggle.com/miklgr500/cqt-g2net-v2-4-5)\n    * [CQT G2Net V2 [6 - 7]](https://www.kaggle.com/miklgr500/cqt-g2net-v2-6-7)\n    * [CQT G2Net V2 [8 - 9]](https://www.kaggle.com/miklgr500/cqt-g2net-v2-8-9)\n    * [CQT G2Net V2 [10 - 11]](https://www.kaggle.com/miklgr500/cqt-g2net-v2-10-11)\n    * [CQT G2Net V2 [12 - 13]](https://www.kaggle.com/miklgr500/cqt-g2net-v2-12-13)\n    * [CQT G2Net V2 [14 - 15]](https://www.kaggle.com/miklgr500/cqt-g2net-v2-14-15)","metadata":{}},{"cell_type":"markdown","source":"# Next steps\n* Generate Test Sets\n* Create Inference Notebook\n* Add augmentation\n* Add TTA Inference","metadata":{}}]}