{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q efficientnet\n!pip install -q tensorflow-addons\n!pip install -q tf-madgrad\n!pip install -q git+https://github.com//Kevin-McIsaac/cmorlet-tensorflow@Performance --no-deps\n!pip install keras==\"2.4.0\"\nfrom sklearn.metrics import roc_auc_score\nimport re\nimport sys\nsys.path.append(\"Sharpness-Aware-Minimization-TensorFlow\")\nimport os\nimport numpy as np\nimport pandas as pd\nfrom scipy.signal import get_window\nfrom typing import Optional, Tuple\nimport warnings\nimport random\nimport math\nimport tensorflow as tf\nimport efficientnet.tfkeras as efn\nfrom sklearn import metrics\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras import mixed_precision\nimport tensorflow_addons as tfa\nfrom sklearn.model_selection import KFold\nfrom pathlib import Path\n","metadata":{"id":"e9ffa754","outputId":"9b57cb29-f02a-4fb2-c07d-76cc7e32db57","execution":{"iopub.status.busy":"2021-09-19T10:09:35.219431Z","iopub.execute_input":"2021-09-19T10:09:35.220062Z","iopub.status.idle":"2021-09-19T10:10:24.870075Z","shell.execute_reply.started":"2021-09-19T10:09:35.219941Z","shell.execute_reply":"2021-09-19T10:10:24.868915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to create our EfficientNetB7 model\n!pip install -U git+https://github.com/leondgarse/keras_efficientnet_v2\nimport keras_efficientnet_v2\n","metadata":{"execution":{"iopub.status.busy":"2021-09-19T10:10:24.872843Z","iopub.execute_input":"2021-09-19T10:10:24.873144Z","iopub.status.idle":"2021-09-19T10:10:35.393295Z","shell.execute_reply.started":"2021-09-19T10:10:24.873103Z","shell.execute_reply":"2021-09-19T10:10:35.39215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to get hardware strategy\ndef get_hardware_strategy():\n    try:\n\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n        print('Running on TPU ', tpu.master())\n    except ValueError:\n        tpu = None\n\n    if tpu:\n        tf.config.experimental_connect_to_cluster(tpu)\n        tf.tpu.experimental.initialize_tpu_system(tpu)\n        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n\n        tf.config.optimizer.set_jit(True)\n    else:\n        # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n        strategy = tf.distribute.get_strategy()\n\n    print(\"REPLICAS: \", strategy.num_replicas_in_sync)\n    return tpu, strategy\n\n\ntpu, strategy = get_hardware_strategy()","metadata":{"execution":{"iopub.status.busy":"2021-09-19T10:10:35.395505Z","iopub.execute_input":"2021-09-19T10:10:35.395907Z","iopub.status.idle":"2021-09-19T10:10:40.948666Z","shell.execute_reply.started":"2021-09-19T10:10:35.395856Z","shell.execute_reply":"2021-09-19T10:10:40.947641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SAVEDIR = Path(\"models\")\nSAVEDIR.mkdir(exist_ok=True)\n\nOOFDIR = Path(\"oof\")\nOOFDIR.mkdir(exist_ok=True)\n\nREPLICAS = strategy.num_replicas_in_sync\n\nEPOCHS = 18\nBATCH_SIZE = 16\nIMAGE_SIZE = [512,512]\n\n# Seed\nSEED = 2021\nLR = 0.0001\nVERBOSE = 1\nNUM_FOLDS = 4","metadata":{"execution":{"iopub.status.busy":"2021-09-19T10:10:40.950786Z","iopub.execute_input":"2021-09-19T10:10:40.951573Z","iopub.status.idle":"2021-09-19T10:10:40.959222Z","shell.execute_reply.started":"2021-09-19T10:10:40.951522Z","shell.execute_reply":"2021-09-19T10:10:40.958144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# strategy.num_replicas_in_sync","metadata":{"id":"7b2498d1","outputId":"f9e2037a-bdb4-4b10-a2e8-ca4e9772740d","execution":{"iopub.status.busy":"2021-09-19T10:10:40.9611Z","iopub.execute_input":"2021-09-19T10:10:40.961448Z","iopub.status.idle":"2021-09-19T10:10:40.97838Z","shell.execute_reply.started":"2021-09-19T10:10:40.9614Z","shell.execute_reply":"2021-09-19T10:10:40.977046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# For tf.dataset\nAUTO = tf.data.experimental.AUTOTUNE\n\nGCS_PATH1 = \"gs://kds-0ce57d316a43123380114b5d7ad7220bd2d98bc2d2ca3c6b12066dcb\"\nGCS_PATH2 = \"gs://kds-00963e1b0402e5e11824a284b3c7b57cc1aa90a7f848ca0f70ea02c1\"\nGCS_PATH3 = \"gs://kds-0a1b764bbf29152f53ab0a3271970056596514c6dc3c05f74e5bc3ad\"\n# Data access (Test tf records)\nGCS_PATH4 = \"gs://kds-0f37e33fcfe9fece00f03f55c79d28611c576e844d1293ba786136ea\"\nGCS_PATH5 = \"gs://kds-cc48964f90b8da9c9d79a6c8c500e7aae7fd9d6dc69f243deb29b5c9\"\n\n\n\n# Training filenames directory\nTRAINING_FILENAMES = tf.io.gfile.glob(GCS_PATH1 + '/train*.tfrec') + tf.io.gfile.glob(\n    GCS_PATH2 + '/train*.tfrec') + tf.io.gfile.glob(GCS_PATH3 + '/train*.tfrec')\n# Testing filenames directory\nTESTING_FILENAMES = tf.io.gfile.glob(GCS_PATH4 + '/test*.tfrec') + tf.io.gfile.glob(GCS_PATH5 + '/test*.tfrec')","metadata":{"id":"3ed66213","execution":{"iopub.status.busy":"2021-09-19T10:10:40.981341Z","iopub.execute_input":"2021-09-19T10:10:40.982047Z","iopub.status.idle":"2021-09-19T10:10:41.351587Z","shell.execute_reply.started":"2021-09-19T10:10:40.981986Z","shell.execute_reply":"2021-09-19T10:10:41.350829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to create cqt kernel\ndef create_cqt_kernels(\n        q: float,\n        fs: float,\n        fmin: float,\n        n_bins: int = 84,\n        bins_per_octave: int = 12,\n        norm: float = 1,\n        window: str = \"hann\",\n        fmax: Optional[float] = None,\n        topbin_check: bool = True\n) -> Tuple[np.ndarray, int, np.ndarray, float]:\n    fft_len = 2 ** _nextpow2(np.ceil(q * fs / fmin))\n\n    if (fmax is not None) and (n_bins is None):\n        n_bins = np.ceil(bins_per_octave * np.log2(fmax / fmin))\n        freqs = fmin * 2.0 ** (np.r_[0:n_bins] / np.float(bins_per_octave))\n    elif (fmax is None) and (n_bins is not None):\n        freqs = fmin * 2.0 ** (np.r_[0:n_bins] / np.float(bins_per_octave))\n    else:\n        warnings.warn(\"If nmax is given, n_bins will be ignored\", SyntaxWarning)\n        n_bins = np.ceil(bins_per_octave * np.log2(fmax / fmin))\n        freqs = fmin * 2.0 ** (np.r_[0:n_bins] / np.float(bins_per_octave))\n\n    if np.max(freqs) > fs / 2 and topbin_check:\n        raise ValueError(f\"The top bin {np.max(freqs)} Hz has exceeded the Nyquist frequency, \\\n                           please reduce the `n_bins`\")\n\n    kernel = np.zeros((int(n_bins), int(fft_len)), dtype=np.complex64)\n\n    length = np.ceil(q * fs / freqs)\n    for k in range(0, int(n_bins)):\n        freq = freqs[k]\n        l = np.ceil(q * fs / freq)\n\n        if l % 2 == 1:\n            start = int(np.ceil(fft_len / 2.0 - l / 2.0)) - 1\n        else:\n            start = int(np.ceil(fft_len / 2.0 - l / 2.0))\n\n        sig = get_window(window, int(l), fftbins=True) * np.exp(\n            np.r_[-l // 2:l // 2] * 1j * 2 * np.pi * freq / fs) / l\n\n        if norm:\n            kernel[k, start:start + int(l)] = sig / np.linalg.norm(sig, norm)\n        else:\n            kernel[k, start:start + int(l)] = sig\n    return kernel, fft_len, length, freqs\n\n\n\ndef _nextpow2(a: float) -> int:\n    return int(np.ceil(np.log2(a)))\n\n\n# Function to prepare cqt kernel\ndef prepare_cqt_kernel(\n\t\tsr=22050,\n\t\thop_length=512,\n\t\tfmin=32.70,\n\t\tfmax=None,\n\t\tn_bins=84,\n\t\tbins_per_octave=12,\n\t\tnorm=1,\n\t\tfilter_scale=1,\n\t\twindow=\"hann\"\n):\n\tq = float(filter_scale) / (2 ** (1 / bins_per_octave) - 1)\n\tprint(q)\n\treturn create_cqt_kernels(q, sr, fmin, n_bins, bins_per_octave, norm, window, fmax)\n\n\n# Function to create cqt image\nfrom CWT.cwt import ComplexMorletCWT\n\ncwt_transform = ComplexMorletCWT(wavelet_width=8, fs=2048, lower_freq=20, upper_freq=1024, n_scales=IMAGE_SIZE[0],\n                                 stride=int(np.ceil(4096 / IMAGE_SIZE[0])), output='magnitude',\n                                 data_format='channels_first')\n\n\ndef create_cqt_image(wave, hop_length=16):\n\tCQTs = []\n\n\tCQT = cwt_transform(tf.expand_dims(wave, axis=0))\n\tCQTs.append(CQT)\n\treturn tf.convert_to_tensor(CQTs)\n\n\nHOP_LENGTH = 6\ncqt_kernels, KERNEL_WIDTH, lengths, _ = prepare_cqt_kernel(\n    sr=2048,\n    hop_length=HOP_LENGTH,\n    fmin=20,\n    fmax=1024,\n    bins_per_octave=9)\nLENGTHS = tf.constant(lengths, dtype=tf.float32)\nCQT_KERNELS_REAL = tf.constant(np.swapaxes(cqt_kernels.real[:, np.newaxis, :], 0, 2))\nCQT_KERNELS_IMAG = tf.constant(np.swapaxes(cqt_kernels.imag[:, np.newaxis, :], 0, 2))\nPADDING = tf.constant([[0, 0],\n                       [KERNEL_WIDTH // 2, KERNEL_WIDTH // 2],\n                       [0, 0]])\n","metadata":{"id":"b7dc991a","outputId":"547c409d-cfb7-46af-8910-8d55eb12d6e8","execution":{"iopub.status.busy":"2021-09-19T10:10:41.352936Z","iopub.execute_input":"2021-09-19T10:10:41.35335Z","iopub.status.idle":"2021-09-19T10:10:42.742438Z","shell.execute_reply.started":"2021-09-19T10:10:41.353317Z","shell.execute_reply":"2021-09-19T10:10:42.741479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class GeMPoolingLayer(tf.keras.layers.Layer):\n    def __init__(self, p=1., train_p=False):\n        super().__init__()\n        if train_p:\n            self.p = tf.Variable(p, dtype=tf.float32)\n        else:\n            self.p = p\n        self.eps = 1e-6\n\n    def call(self, inputs: tf.Tensor, **kwargs):\n        inputs = tf.clip_by_value(inputs, clip_value_min=1e-6, clip_value_max=tf.reduce_max(inputs))\n        inputs = tf.pow(inputs, self.p)\n        inputs = tf.reduce_mean(inputs, axis=[1, 2], keepdims=False)\n        inputs = tf.pow(inputs, 1. / self.p)\n        return inputs\ndef seed_everything(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    tf.random.set_seed(seed)\n\n\n# Function to prepare image\ndef prepare_image(wave, dim=512):\n    # Decode raw\n    wave = tf.reshape(tf.io.decode_raw(wave, tf.float64), (3, 4096))\n    scaling = tf.constant([1.5e-20, 1.5e-20, 0.5e-20], dtype=tf.float64)\n\n    normalized_waves = []\n    # Normalize\n    for i in range(3):\n        normalized_wave = wave[i] / scaling[i]\n        normalized_waves.append(normalized_wave)\n    wave = tf.stack(normalized_waves)\n    wave = tf.cast(wave, tf.float32)\n    image = create_cqt_image(wave, HOP_LENGTH)\n    image = tf.transpose(image[0, 0, :, :, :])\n    image = tf.image.resize(image, size=(dim, dim))\n    return tf.reshape(image, (dim, dim, 3))\n\n\n\n# This function parse our images and also get the target variable\ndef read_labeled_tfrecord(example):\n    LABELED_TFREC_FORMAT = {\n        'wave': tf.io.FixedLenFeature([], tf.string),\n        'wave_id': tf.io.FixedLenFeature([], tf.string),\n        'target': tf.io.FixedLenFeature([], tf.int64)\n    }\n    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n    image = prepare_image(example['wave'])\n    image_id = example['wave_id']\n    target = tf.cast(example['target'], tf.float32)\n    return image, image_id, target\n\n\n# This function parse our images and also get the target variable\ndef read_unlabeled_tfrecord(example):\n    LABELED_TFREC_FORMAT = {\n        'wave': tf.io.FixedLenFeature([], tf.string),\n        'wave_id': tf.io.FixedLenFeature([], tf.string)\n    }\n    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n    image = prepare_image(example['wave'])\n    image_id = example['wave_id']\n    return image, image_id\n\n\n# This function loads TF Records and parse them into tensors\ndef load_dataset(filenames, ordered=False, labeled=True):\n    ignore_order = tf.data.Options()\n    if not ordered:\n        ignore_order.experimental_deterministic = False\n\n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO)\n    dataset = dataset.with_options(ignore_order)\n    dataset = dataset.map(read_labeled_tfrecord if labeled else read_unlabeled_tfrecord, num_parallel_calls=AUTO)\n    return dataset\n\n\n# This function is to get our training dataset\ndef get_training_dataset(filenames, batch_size=32, ordered=False, labeled=True, train=True, get_ids=False):\n    dataset = load_dataset(filenames, ordered=ordered, labeled=labeled)\n    if train:\n        dataset = dataset.repeat()\n        dataset = dataset.shuffle(2048)\n    dataset = dataset.batch(batch_size*REPLICAS)\n    dataset = dataset.prefetch(AUTO)\n    \n    if get_ids:\n        dataset = dataset.map(lambda image, image_id: (image, image_id))\n    else:\n        dataset = dataset.map(lambda image, image_id, target: (image, target))\n\n    return dataset\n\n\n# This function is to get our validation and test dataset\ndef get_val_test_dataset(filenames, ordered=True, labeled=True):\n    dataset = load_dataset(filenames, ordered=ordered, labeled=labeled)\n    dataset = dataset.batch(BATCH_SIZE*REPLICAS)\n    dataset = dataset.prefetch(AUTO)\n    return dataset\n\n\n# Function to count how many photos we have in\ndef count_data_items(filenames):\n    # The number of data items is written in the name of the .tfrec files, i.e. flowers00-230.tfrec = 230 data items\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n    return np.sum(n)\n\n\nNUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\nNUM_TESTING_IMAGES = count_data_items(TESTING_FILENAMES)\nprint(f'Dataset: {NUM_TRAINING_IMAGES} training images')\nprint(f'Dataset: {NUM_TESTING_IMAGES} testing images')\n","metadata":{"id":"cb44cdfa","outputId":"8ffa3704-7f89-4b11-c626-90cafc081e56","execution":{"iopub.status.busy":"2021-09-19T10:35:14.030274Z","iopub.execute_input":"2021-09-19T10:35:14.030621Z","iopub.status.idle":"2021-09-19T10:35:14.062509Z","shell.execute_reply.started":"2021-09-19T10:35:14.030576Z","shell.execute_reply":"2021-09-19T10:35:14.061519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SAM():\n    def __init__(self, base_optimizer, rho=0.05):\n        assert rho >= 0.0, f\"Invalid rho, should be non-negative: {rho}\"\n\n        self.rho = rho\n        self.base_optimizer = base_optimizer\n\n    def first_step(self, gradients, trainable_variables):\n        self.e_ws = []\n        grad_norm = tf.linalg.global_norm(gradients)\n        for i in range(len(trainable_variables)):\n            e_w = gradients[i] * self.rho / (grad_norm + 1e-12)\n            trainable_variables[i].assign_add(e_w)\n            self.e_ws.append(e_w)\n\n    def second_step(self, gradients, trainable_variables):\n        for i in range(len(trainable_variables)):\n            trainable_variables[i].assign_add(-self.e_ws[i])\n        # do the actual \"sharpness-aware\" update\n        self.base_optimizer.apply_gradients(zip(gradients, trainable_variables))\n\n\n# if you want to use model.fit(), override the train_step method of a model with this function, example is mnist_example_keras_fit.\n# for customization see https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit/\ndef sam_train_step(self, data, rho=0.05, eps=1e-12):\n    # Unpack the data. Its structure depends on your model and\n    # on what you pass to `fit()`.\n    if len(data) == 3:\n        x, y, sample_weight = data\n    else:\n        sample_weight = None\n        x, y = data\n\n    with tf.GradientTape() as tape:\n        y_pred = self(x, training=True)  # Forward pass\n        # Compute the loss value\n        # (the loss function is configured in `compile()`)\n        loss = self.compiled_loss(y, y_pred, sample_weight=sample_weight, regularization_losses=self.losses)\n\n    # Compute gradients\n    trainable_vars = self.trainable_variables\n    gradients = tape.gradient(loss, trainable_vars)\n\n    # first step\n    e_ws = []\n    grad_norm = tf.linalg.global_norm(gradients)\n    for i in range(len(trainable_vars)):\n        e_w = gradients[i] * rho / (grad_norm + eps)\n        trainable_vars[i].assign_add(e_w)\n        e_ws.append(e_w)\n\n    with tf.GradientTape() as tape:\n        y_pred = self(x, training=True)  # Forward pass\n        # Compute the loss value\n        # (the loss function is configured in `compile()`)\n        loss = self.compiled_loss(y, y_pred, sample_weight=sample_weight, regularization_losses=self.losses)\n\n    trainable_vars = self.trainable_variables\n    gradients = tape.gradient(loss, trainable_vars)\n\n    for i in range(len(trainable_vars)):\n        trainable_vars[i].assign_sub(e_ws[i])\n    self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n\n    # Update the metrics.\n    # Metrics are configured in `compile()`.\n    self.compiled_metrics.update_state(y, y_pred, sample_weight=sample_weight)\n\n    # Return a dict mapping metric names to current value.\n    # Note that it will include the loss (tracked in self.metrics).\n    return {m.name: m.result() for m in self.metrics}\n","metadata":{"id":"0cdb375b","outputId":"850c7ad7-5899-45d9-bf0e-15a18f13b90b","execution":{"iopub.status.busy":"2021-09-19T10:10:42.789928Z","iopub.execute_input":"2021-09-19T10:10:42.790201Z","iopub.status.idle":"2021-09-19T10:10:42.824113Z","shell.execute_reply.started":"2021-09-19T10:10:42.790169Z","shell.execute_reply":"2021-09-19T10:10:42.82219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Learning rate callback function\ndef get_lr_callback():\n    lr_start = 0.0001\n    lr_max = 0.000015 * BATCH_SIZE\n    lr_min = 0.0000001\n    lr_ramp_ep = 3\n    lr_sus_ep = 0\n    lr_decay = 0.7\n\n    def lrfn(epoch):\n        if epoch < lr_ramp_ep:\n            lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n        elif epoch < lr_ramp_ep + lr_sus_ep:\n            lr = lr_max\n        else:\n            lr = (lr_max - lr_min) * lr_decay ** (epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n        return lr\n\n    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=VERBOSE)\n    return lr_callback\n\n\nimport math\nfrom tensorflow.keras.callbacks import Callback\nfrom tensorflow.keras import backend as K\n\n\nclass CosineAnnealingScheduler(Callback):\n    \"\"\"Cosine annealing scheduler.\n    \"\"\"\n\n    def __init__(self, T_max, eta_max, eta_min=0, verbose=0):\n        super(CosineAnnealingScheduler, self).__init__()\n        self.T_max = T_max\n        self.eta_max = eta_max\n        self.eta_min = eta_min\n        self.verbose = verbose\n\n    def on_epoch_begin(self, epoch, logs=None):\n        if not hasattr(self.model.optimizer, 'lr'):\n            raise ValueError('Optimizer must have a \"lr\" attribute.')\n        lr = self.eta_min + (self.eta_max - self.eta_min) * (1 + math.cos(math.pi * epoch / self.T_max)) / 2\n        K.set_value(self.model.optimizer.lr, lr)\n        if self.verbose > 0:\n            print('\\nEpoch %05d: CosineAnnealingScheduler setting learning '\n                  'rate to %s.' % (epoch + 1, lr))\n\n    def on_epoch_end(self, epoch, logs=None):\n        logs = logs or {}\n        logs['lr'] = K.get_value(self.model.optimizer.lr)\n\n\ndecay = CosineAnnealingScheduler(T_max=100, eta_max=1e-3, eta_min=1e-6)","metadata":{"execution":{"iopub.status.busy":"2021-09-19T10:10:42.829076Z","iopub.execute_input":"2021-09-19T10:10:42.829426Z","iopub.status.idle":"2021-09-19T10:10:42.847171Z","shell.execute_reply.started":"2021-09-19T10:10:42.829371Z","shell.execute_reply":"2021-09-19T10:10:42.846328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=1213)\n","metadata":{"execution":{"iopub.status.busy":"2021-09-19T10:10:42.848368Z","iopub.execute_input":"2021-09-19T10:10:42.849062Z","iopub.status.idle":"2021-09-19T10:10:42.869203Z","shell.execute_reply.started":"2021-09-19T10:10:42.849013Z","shell.execute_reply":"2021-09-19T10:10:42.867773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# options = tf.train.CheckpointOptions(experimental_io_device=\"/job:localhost\")\n# model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n#     filepath=\"Temp.h5\",\n#     save_weights_only=True,\n#     monitor='auc',\n#     mode='max',\n#     save_best_only=True, options=options)\n\n\n# Function to train a model with 100% of the data\ndef train_and_evaluate(SEED=42):\n    print('\\n')\n    print('-' * 50)\n#     print(f'Training EFFB0 with 100% of the data with seed {SEED} for {EPOCHS} epochs')\n    print(f'Training EFFB0 with FOLDWISE of the data with seed {SEED} for {EPOCHS} epochs')\n    if tpu:\n        tf.tpu.experimental.initialize_tpu_system(tpu)\n    train_dataset = get_training_dataset(TRAINING_FILENAMES, ordered=False, labeled=True)\n    train_dataset = train_dataset.map(lambda image, image_id, target: (image, target))\n    STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // (BATCH_SIZE * 4)\n    K.clear_session()\n    # Seed everything\n    seed_everything(SEED)\n    model = get_model()\n    history = model.fit(train_dataset,\n                        steps_per_epoch=STEPS_PER_EPOCH,\n                        epochs=EPOCHS,\n                        callbacks=[get_lr_callback(), model_checkpoint_callback],\n                        verbose=1)\n\n    print('\\n')\n    print('-' * 50)\n    print('Test inference...')\n    model = model.load_weights(\"content/Temp\", options=options)\n    # Predict the test set\n    dataset = get_val_test_dataset(TESTING_FILENAMES, ordered=True, labeled=False)\n    image = dataset.map(lambda image, image_id: image)\n    test_predictions = model.predict(image).astype(np.float32).reshape(-1)\n    # Get the test set image_id\n    image_id = dataset.map(lambda image, image_id: image_id).unbatch()\n    image_id = next(iter(image_id.batch(NUM_TESTING_IMAGES))).numpy().astype('U')\n    # Create dataframe output\n    test_df = pd.DataFrame({'id': image_id, 'target': test_predictions})\n    # Save test dataframe to disk\n    test_df.to_csv(f'TEST_xEfficientNetB7_{IMAGE_SIZE[0]}_{SEED}.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2021-09-19T10:10:42.871076Z","iopub.execute_input":"2021-09-19T10:10:42.871457Z","iopub.status.idle":"2021-09-19T10:10:42.891147Z","shell.execute_reply.started":"2021-09-19T10:10:42.871417Z","shell.execute_reply":"2021-09-19T10:10:42.889767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_model():\n    inp = tf.keras.layers.Input(shape=(*IMAGE_SIZE, 3))\n    x = efn.EfficientNetB7(include_top=False, weights='noisy-student')(inp)\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    output = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n    model = tf.keras.models.Model(inputs=[inp], outputs=[output])\n    opt = tf.keras.optimizers.Adam(learning_rate=LR)\n    opt = tfa.optimizers.SWA(opt)\n    model.compile(\n        optimizer=opt,\n        loss=[tf.keras.losses.BinaryCrossentropy()],\n        metrics=[tf.keras.metrics.AUC()]\n    )\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-09-19T10:10:42.892527Z","iopub.execute_input":"2021-09-19T10:10:42.893244Z","iopub.status.idle":"2021-09-19T10:10:42.912013Z","shell.execute_reply.started":"2021-09-19T10:10:42.893201Z","shell.execute_reply":"2021-09-19T10:10:42.911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"files_train_all = np.array(TRAINING_FILENAMES)","metadata":{"execution":{"iopub.status.busy":"2021-09-19T10:10:42.930736Z","iopub.execute_input":"2021-09-19T10:10:42.931176Z","iopub.status.idle":"2021-09-19T10:10:42.944073Z","shell.execute_reply.started":"2021-09-19T10:10:42.931129Z","shell.execute_reply":"2021-09-19T10:10:42.942767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfor fold, (trn_idx, val_idx) in enumerate(kf.split(files_train_all)):\n    \n    oof_pred = []\n    oof_target = []\n    oof_img_ids=[]\n    \n    \n    files_train = files_train_all[trn_idx]\n    files_valid = files_train_all[val_idx]\n    \n    if fold!=3:\n        continue\n    \n    print(\"=\" * 120)\n    print(f\"Fold {fold}\")\n    print(\"=\" * 120)\n\n    K.clear_session()\n    # Seed everything\n    seed_everything(SEED)\n    \n    \n    train_image_count = count_data_items(files_train)\n    valid_image_count = count_data_items(files_valid)\n    \n    print(f'Dataset: {train_image_count} training images')\n    print(f'Dataset: {valid_image_count} valid images')\n\n    tf.keras.backend.clear_session()\n    \n\n    with strategy.scope():\n        model = get_model()\n        \n        \n    options = tf.train.CheckpointOptions(experimental_io_device=\"/job:localhost\")    \n    \n    model_ckpt = tf.keras.callbacks.ModelCheckpoint(\n        str(SAVEDIR / f\"fold{fold}.h5\"), monitor=\"val_auc\", verbose=1, save_best_only=True,\n        save_weights_only=True, mode=\"max\", save_freq=\"epoch\"\n    )\n    \n    STEPS_PER_EPOCH = train_image_count // BATCH_SIZE // REPLICAS // 4\n    \n    history = model.fit(\n        get_training_dataset(files_train,batch_size=BATCH_SIZE, ordered=False, labeled=True),\n        steps_per_epoch=STEPS_PER_EPOCH,\n        epochs=EPOCHS,\n        callbacks=[get_lr_callback(), model_ckpt],\n        validation_data=get_training_dataset(files_valid,batch_size=BATCH_SIZE*4, ordered=False, labeled=True, train=False),\n        verbose=1\n    )\n        \n    print(\"Loading best model...\")\n    model.load_weights(str(SAVEDIR / f\"fold{fold}.h5\"))\n        \n    ds_valid = get_training_dataset(files_valid, ordered=True, labeled=True, train=False) \n\n    STEPS = np.ceil(valid_image_count / BATCH_SIZE  / REPLICAS)\n    pred = model.predict(ds_valid, steps=STEPS, verbose=1)[:valid_image_count]    \n    oof_pred.append(np.mean(pred.reshape((valid_image_count, 1), order=\"F\"), axis=1))\n\n    ds_valid = get_training_dataset(files_valid, ordered=True, labeled=True, train=False)  \n    oof_target.append(np.array([target.numpy() for img, target  in iter(ds_valid.unbatch())]))\n    \n    \n    ds_valid = get_training_dataset(files_valid, ordered=True, labeled=False, train=False, get_ids=True)\n    oof_img_ids.append(np.array([target.numpy() for img, target in iter(ds_valid.unbatch())]))    \n    \n    oof = np.concatenate(oof_pred)\n    true = np.concatenate(oof_target)\n    auc = roc_auc_score(y_true=true, y_score=oof)\n    print(f\"VAL AUC: {auc:.5f}\")\n    \n    \n    img_ids = np.concatenate(oof_img_ids)\n\n    df = pd.DataFrame({\n        \"id\":img_ids,\n        \"y_true\": true.reshape(-1),\n        \"y_pred\": oof\n    })\n    df.head()\n    df.to_csv(OOFDIR / f\"oof_512_b7_fold{fold}.csv\", index=False)\n    ","metadata":{"execution":{"iopub.status.busy":"2021-09-19T10:36:06.20354Z","iopub.execute_input":"2021-09-19T10:36:06.203921Z","iopub.status.idle":"2021-09-19T10:38:02.664257Z","shell.execute_reply.started":"2021-09-19T10:36:06.203885Z","shell.execute_reply":"2021-09-19T10:38:02.662953Z"},"trusted":true},"execution_count":null,"outputs":[]}]}