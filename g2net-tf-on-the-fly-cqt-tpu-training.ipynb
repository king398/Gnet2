{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## About this notebook\n",
    "\n",
    "This notebook is based on [CQT G2Net EfficientNetB1[TPU Training]](https://www.kaggle.com/miklgr500/cqt-g2net-efficientnetb7-tpu-training-w-b) by [Welf Crozzo](https://www.kaggle.com/miklgr500) and [nnAudio Constant Q-transform Demonstration](https://www.kaggle.com/atamazian/nnaudio-constant-q-transform-demonstration) by [Araik Tamazian](https://www.kaggle.com/atamazian).\n",
    "\n",
    "This notebook use Constant Q-Transform for feature extraction and EfficientNetB0 for classification. The whole pipeline is implemented with Tensorflow, and the training process runs on TPU.\n",
    "\n",
    "The main difference between this notebook and Welf's notebook is the use of on-the-fly CQT computation implemented with Tensorflow, which is similar to the idea of [nnAudio](https://github.com/KinWaiCheuk/nnAudio)'s [CQT1992v2](https://kinwaicheuk.github.io/nnAudio/_autosummary/nnAudio.Spectrogram.CQT1992v2.html?highlight=cqt1992v2#nnAudio.Spectrogram.CQT1992v2) layer.\n",
    "\n",
    "* [Inference Notebook](https://www.kaggle.com/hidehisaarai1213/g2net-tf-on-the-fly-cqt-tpu-inference)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Install Dependencies"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install efficientnet tensorflow_addons > / dev / null"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-22T14:19:36.103250Z",
     "iopub.execute_input": "2021-08-22T14:19:36.103726Z",
     "iopub.status.idle": "2021-08-22T14:19:45.554707Z",
     "shell.execute_reply.started": "2021-08-22T14:19:36.103627Z",
     "shell.execute_reply": "2021-08-22T14:19:45.553646Z"
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "text": "\u001B[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001B[0m\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import re\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "import efficientnet.tfkeras as efn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from kaggle_datasets import KaggleDatasets\n",
    "from scipy.signal import get_window\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-22T14:19:45.556833Z",
     "iopub.execute_input": "2021-08-22T14:19:45.557171Z",
     "iopub.status.idle": "2021-08-22T14:19:53.542839Z",
     "shell.execute_reply.started": "2021-08-22T14:19:45.557136Z",
     "shell.execute_reply": "2021-08-22T14:19:53.541914Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tf.__version__"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-22T14:19:53.544618Z",
     "iopub.execute_input": "2021-08-22T14:19:53.545144Z",
     "iopub.status.idle": "2021-08-22T14:19:53.553488Z",
     "shell.execute_reply.started": "2021-08-22T14:19:53.545107Z",
     "shell.execute_reply": "2021-08-22T14:19:53.552449Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": [
    {
     "execution_count": 3,
     "output_type": "execute_result",
     "data": {
      "text/plain": "'2.4.1'"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Config"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "NUM_FOLDS = 4\n",
    "IMAGE_SIZE = 256\n",
    "BATCH_SIZE = 32\n",
    "EFFICIENTNET_SIZE = 7\n",
    "WEIGHTS = \"imagenet\"\n",
    "\n",
    "MIXUP_PROB = 0.0\n",
    "EPOCHS = 20\n",
    "R_ANGLE = 0 / 180 * np.pi\n",
    "S_SHIFT = 0.0\n",
    "T_SHIFT = 0.0\n",
    "LABEL_POSITIVE_SHIFT = 0.99"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-22T14:19:53.555464Z",
     "iopub.execute_input": "2021-08-22T14:19:53.555956Z",
     "iopub.status.idle": "2021-08-22T14:19:53.569816Z",
     "shell.execute_reply.started": "2021-08-22T14:19:53.555920Z",
     "shell.execute_reply": "2021-08-22T14:19:53.568835Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "SAVEDIR = Path(\"models\")\n",
    "SAVEDIR.mkdir(exist_ok=True)\n",
    "\n",
    "OOFDIR = Path(\"oof\")\n",
    "OOFDIR.mkdir(exist_ok=True)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-22T14:19:53.570912Z",
     "iopub.execute_input": "2021-08-22T14:19:53.571343Z",
     "iopub.status.idle": "2021-08-22T14:19:53.585025Z",
     "shell.execute_reply.started": "2021-08-22T14:19:53.571311Z",
     "shell.execute_reply": "2021-08-22T14:19:53.584170Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Utilities"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def set_seed(seed=42):\n",
    "\trandom.seed(seed)\n",
    "\tos.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\tnp.random.seed(seed)\n",
    "\ttf.random.set_seed(seed)\n",
    "\n",
    "\n",
    "set_seed(1213)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-22T14:19:53.586220Z",
     "iopub.execute_input": "2021-08-22T14:19:53.586999Z",
     "iopub.status.idle": "2021-08-22T14:19:53.598850Z",
     "shell.execute_reply.started": "2021-08-22T14:19:53.586957Z",
     "shell.execute_reply": "2021-08-22T14:19:53.598021Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def auto_select_accelerator():\n",
    "\tTPU_DETECTED = False\n",
    "\ttry:\n",
    "\t\ttpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "\t\ttf.config.experimental_connect_to_cluster(tpu)\n",
    "\t\ttf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "\t\tstrategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "\t\tprint(\"Running on TPU:\", tpu.master())\n",
    "\t\tTPU_DETECTED = True\n",
    "\texcept ValueError:\n",
    "\t\tstrategy = tf.distribute.get_strategy()\n",
    "\tprint(f\"Running on {strategy.num_replicas_in_sync} replicas\")\n",
    "\n",
    "\treturn strategy, TPU_DETECTED"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-22T14:19:53.600159Z",
     "iopub.execute_input": "2021-08-22T14:19:53.600672Z",
     "iopub.status.idle": "2021-08-22T14:19:53.619817Z",
     "shell.execute_reply.started": "2021-08-22T14:19:53.600637Z",
     "shell.execute_reply": "2021-08-22T14:19:53.618920Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "strategy, tpu_detected = auto_select_accelerator()\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "REPLICAS = strategy.num_replicas_in_sync"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-22T14:19:53.622206Z",
     "iopub.execute_input": "2021-08-22T14:19:53.622772Z",
     "iopub.status.idle": "2021-08-22T14:19:59.432505Z",
     "shell.execute_reply.started": "2021-08-22T14:19:53.622735Z",
     "shell.execute_reply": "2021-08-22T14:19:59.431443Z"
    },
    "trusted": true
   },
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "text": "Running on TPU: grpc://10.0.0.2:8470\nRunning on 8 replicas\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Loading"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "gcs_paths = []\n",
    "for i, j in [(0, 4), (5, 9), (10, 14), (15, 19)]:\n",
    "\tGCS_path = KaggleDatasets().get_gcs_path(f\"g2net-waveform-tfrecords-train-{i}-{j}\")\n",
    "\tgcs_paths.append(GCS_path)\n",
    "\tprint(GCS_path)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-22T14:19:59.436322Z",
     "iopub.execute_input": "2021-08-22T14:19:59.436664Z",
     "iopub.status.idle": "2021-08-22T14:20:00.919669Z",
     "shell.execute_reply.started": "2021-08-22T14:19:59.436634Z",
     "shell.execute_reply": "2021-08-22T14:20:00.918735Z"
    },
    "trusted": true
   },
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "text": "gs://kds-661c1fac95c960fc4df2e0c0a73b70453e8ddf66aeece6e80be9d7e7\ngs://kds-2a98eb75dd55a7566f5ca648f0fd2d91e9e5035174fde2fccaef522e\ngs://kds-b509ed8e2fa5c62a13cf076c2ff4c8223b4b0cfb60c78b8427ea5257\ngs://kds-49d03668d4405f2b050774421b04a7a023edc35a83691f50d867e72b\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "all_files = []\n",
    "for path in gcs_paths:\n",
    "\tall_files.extend(np.sort(np.array(tf.io.gfile.glob(path + \"/train*.tfrecords\"))))\n",
    "\n",
    "print(\"train_files: \", len(all_files))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-22T14:20:00.920805Z",
     "iopub.execute_input": "2021-08-22T14:20:00.921254Z",
     "iopub.status.idle": "2021-08-22T14:20:01.232346Z",
     "shell.execute_reply.started": "2021-08-22T14:20:00.921221Z",
     "shell.execute_reply": "2021-08-22T14:20:01.231305Z"
    },
    "trusted": true
   },
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "text": "train_files:  20\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset Preparation\n",
    "\n",
    "Here's the main contribution of this notebook - Tensorflow version of on-the-fly CQT computation. Note that some of the operations used in CQT computation are not supported by TPU, therefore the implementation is not a TF layer but a function that runs on CPU."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def create_cqt_kernels(\n",
    "\t\tq: float,\n",
    "\t\tfs: float,\n",
    "\t\tfmin: float,\n",
    "\t\tn_bins: int = 84,\n",
    "\t\tbins_per_octave: int = 12,\n",
    "\t\tnorm: float = 1,\n",
    "\t\twindow: str = \"hann\",\n",
    "\t\tfmax: Optional[float] = None,\n",
    "\t\ttopbin_check: bool = True\n",
    ") -> Tuple[np.ndarray, int, np.ndarray, float]:\n",
    "\tfft_len = 2 ** _nextpow2(np.ceil(q * fs / fmin))\n",
    "\n",
    "\tif (fmax is not None) and (n_bins is None):\n",
    "\t\tn_bins = np.ceil(bins_per_octave * np.log2(fmax / fmin))\n",
    "\t\tfreqs = fmin * 2.0 ** (np.r_[0:n_bins] / np.float(bins_per_octave))\n",
    "\telif (fmax is None) and (n_bins is not None):\n",
    "\t\tfreqs = fmin * 2.0 ** (np.r_[0:n_bins] / np.float(bins_per_octave))\n",
    "\telse:\n",
    "\t\twarnings.warn(\"If nmax is given, n_bins will be ignored\", SyntaxWarning)\n",
    "\t\tn_bins = np.ceil(bins_per_octave * np.log2(fmax / fmin))\n",
    "\t\tfreqs = fmin * 2.0 ** (np.r_[0:n_bins] / np.float(bins_per_octave))\n",
    "\n",
    "\tif np.max(freqs) > fs / 2 and topbin_check:\n",
    "\t\traise ValueError(f\"The top bin {np.max(freqs)} Hz has exceeded the Nyquist frequency, \\\n",
    "                           please reduce the `n_bins`\")\n",
    "\n",
    "\tkernel = np.zeros((int(n_bins), int(fft_len)), dtype=np.complex64)\n",
    "\n",
    "\tlength = np.ceil(q * fs / freqs)\n",
    "\tfor k in range(0, int(n_bins)):\n",
    "\t\tfreq = freqs[k]\n",
    "\t\tl = np.ceil(q * fs / freq)\n",
    "\n",
    "\t\tif l % 2 == 1:\n",
    "\t\t\tstart = int(np.ceil(fft_len / 2.0 - l / 2.0)) - 1\n",
    "\t\telse:\n",
    "\t\t\tstart = int(np.ceil(fft_len / 2.0 - l / 2.0))\n",
    "\n",
    "\t\tsig = get_window(window, int(l), fftbins=True) * np.exp(\n",
    "\t\t\tnp.r_[-l // 2:l // 2] * 1j * 2 * np.pi * freq / fs) / l\n",
    "\n",
    "\t\tif norm:\n",
    "\t\t\tkernel[k, start:start + int(l)] = sig / np.linalg.norm(sig, norm)\n",
    "\t\telse:\n",
    "\t\t\tkernel[k, start:start + int(l)] = sig\n",
    "\treturn kernel, fft_len, length, freqs\n",
    "\n",
    "\n",
    "def _nextpow2(a: float) -> int:\n",
    "\treturn int(np.ceil(np.log2(a)))\n",
    "\n",
    "\n",
    "def prepare_cqt_kernel(\n",
    "\t\tsr=22050,\n",
    "\t\thop_length=512,\n",
    "\t\tfmin=32.70,\n",
    "\t\tfmax=None,\n",
    "\t\tn_bins=84,\n",
    "\t\tbins_per_octave=12,\n",
    "\t\tnorm=1,\n",
    "\t\tfilter_scale=1,\n",
    "\t\twindow=\"hann\"\n",
    "):\n",
    "\tq = float(filter_scale) / (2 ** (1 / bins_per_octave) - 1)\n",
    "\tprint(q)\n",
    "\treturn create_cqt_kernels(q, sr, fmin, n_bins, bins_per_octave, norm, window, fmax)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-22T14:20:01.233646Z",
     "iopub.execute_input": "2021-08-22T14:20:01.233965Z",
     "iopub.status.idle": "2021-08-22T14:20:01.253303Z",
     "shell.execute_reply.started": "2021-08-22T14:20:01.233929Z",
     "shell.execute_reply": "2021-08-22T14:20:01.252474Z"
    },
    "trusted": true
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "HOP_LENGTH = 16\n",
    "cqt_kernels, KERNEL_WIDTH, lengths, _ = prepare_cqt_kernel(\n",
    "\tsr=2048,\n",
    "\thop_length=HOP_LENGTH,\n",
    "\tfmin=20,\n",
    "\tfmax=1024,\n",
    "\tbins_per_octave=24)\n",
    "LENGTHS = tf.constant(lengths, dtype=tf.float32)\n",
    "CQT_KERNELS_REAL = tf.constant(np.swapaxes(cqt_kernels.real[:, np.newaxis, :], 0, 2))\n",
    "CQT_KERNELS_IMAG = tf.constant(np.swapaxes(cqt_kernels.imag[:, np.newaxis, :], 0, 2))\n",
    "PADDING = tf.constant([[0, 0],\n",
    "                       [KERNEL_WIDTH // 2, KERNEL_WIDTH // 2],\n",
    "                       [0, 0]])"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-22T14:20:01.254875Z",
     "iopub.execute_input": "2021-08-22T14:20:01.255667Z",
     "iopub.status.idle": "2021-08-22T14:20:01.331705Z",
     "shell.execute_reply.started": "2021-08-22T14:20:01.255625Z",
     "shell.execute_reply": "2021-08-22T14:20:01.330134Z"
    },
    "trusted": true
   },
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "text": "34.12708770892056\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:20: SyntaxWarning: If nmax is given, n_bins will be ignored\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "def create_cqt_image(wave, hop_length=16):\n",
    "\twave = tf.random.shuffle(wave)\n",
    "\tCQTs = []\n",
    "\tfor i in range(3):\n",
    "\t\tx = wave[i]\n",
    "\t\tx = tf.expand_dims(tf.expand_dims(x, 0), 2)\n",
    "\t\tx = tf.pad(x, PADDING, \"REFLECT\")\n",
    "\n",
    "\t\tCQT_real = tf.nn.conv1d(x, CQT_KERNELS_REAL, stride=hop_length, padding=\"VALID\")\n",
    "\t\tCQT_imag = -tf.nn.conv1d(x, CQT_KERNELS_IMAG, stride=hop_length, padding=\"VALID\")\n",
    "\t\tCQT_real *= tf.math.sqrt(LENGTHS)\n",
    "\t\tCQT_imag *= tf.math.sqrt(LENGTHS)\n",
    "\n",
    "\t\tCQT = tf.math.sqrt(tf.pow(CQT_real, 2) + tf.pow(CQT_imag, 2))\n",
    "\t\tCQTs.append(CQT[0])\n",
    "\treturn tf.stack(CQTs, axis=2)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-22T14:20:01.333666Z",
     "iopub.execute_input": "2021-08-22T14:20:01.334104Z",
     "iopub.status.idle": "2021-08-22T14:20:01.344274Z",
     "shell.execute_reply.started": "2021-08-22T14:20:01.334056Z",
     "shell.execute_reply": "2021-08-22T14:20:01.342705Z"
    },
    "trusted": true
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "def read_labeled_tfrecord(example):\n",
    "\ttfrec_format = {\n",
    "\t\t\"wave\": tf.io.FixedLenFeature([], tf.string),\n",
    "\t\t\"wave_id\": tf.io.FixedLenFeature([], tf.string),\n",
    "\t\t\"target\": tf.io.FixedLenFeature([], tf.int64)\n",
    "\t}\n",
    "\texample = tf.io.parse_single_example(example, tfrec_format)\n",
    "\treturn prepare_image(example[\"wave\"], IMAGE_SIZE), tf.reshape(tf.cast(example[\"target\"], tf.float32), [1])\n",
    "\n",
    "\n",
    "def read_unlabeled_tfrecord(example, return_image_id):\n",
    "\ttfrec_format = {\n",
    "\t\t\"wave\": tf.io.FixedLenFeature([], tf.string),\n",
    "\t\t\"wave_id\": tf.io.FixedLenFeature([], tf.string)\n",
    "\t}\n",
    "\texample = tf.io.parse_single_example(example, tfrec_format)\n",
    "\treturn prepare_image(example[\"wave\"], IMAGE_SIZE), example[\"wave_id\"] if return_image_id else 0\n",
    "\n",
    "\n",
    "def count_data_items(fileids):\n",
    "\treturn len(fileids) * 28000\n",
    "\n",
    "\n",
    "def count_data_items_test(fileids):\n",
    "\treturn len(fileids) * 22600\n",
    "\n",
    "\n",
    "def mixup(image, label, probability=0.5, aug_batch=64 * 8):\n",
    "\timgs = []\n",
    "\tlabs = []\n",
    "\tfor j in range(aug_batch):\n",
    "\t\tp = tf.cast(tf.random.uniform([], 0, 1) <= probability, tf.float32)\n",
    "\t\tk = tf.cast(tf.random.uniform([], 0, aug_batch), tf.int32)\n",
    "\t\ta = tf.random.uniform([], 0, 1) * p\n",
    "\n",
    "\t\timg1 = image[j]\n",
    "\t\timg2 = image[k]\n",
    "\t\timgs.append((1 - a) * img1 + a * img2)\n",
    "\t\tlab1 = label[j]\n",
    "\t\tlab2 = label[k]\n",
    "\t\tlabs.append((1 - a) * lab1 + a * lab2)\n",
    "\timage2 = tf.reshape(tf.stack(imgs), (aug_batch, IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "\tlabel2 = tf.reshape(tf.stack(labs), (aug_batch,))\n",
    "\treturn image2, label2\n",
    "\n",
    "\n",
    "class CoarseDropout:\n",
    "\tdef __init__(self, max_holes=32, size=0.06):\n",
    "\t\tself.size = size\n",
    "\t\tself.max_holes = max_holes\n",
    "\n",
    "\tdef __call__(self, image):\n",
    "\t\tP = random.uniform(0, 1)\n",
    "\t\theight = image.shape[0]\n",
    "\t\twidth = image.shape[1]\n",
    "\t\tfor _n in range(self.max_holes):\n",
    "\t\t\thole_height = height * self.size * P\n",
    "\t\t\thole_width = width * self.size * P\n",
    "\t\t\thole_height = int(hole_height)\n",
    "\t\t\thole_width = int(hole_width)\n",
    "\t\t\ty1 = random.randint(0, int(height - hole_height))\n",
    "\t\t\tx1 = random.randint(0, int(width - hole_width))\n",
    "\t\t\ty2 = y1 + hole_height\n",
    "\t\t\tx2 = x1 + hole_width\n",
    "\n",
    "\t\t\tone = image[y1:y2, 0:x1, :]\n",
    "\t\t\ttwo = tf.zeros([y2 - y1, x2 - x1, 1], dtype=tf.float32)\n",
    "\t\t\tthree = image[y1:y2, x2:width, :]\n",
    "\t\t\tmiddle = tf.concat([one, two, three], axis=1)\n",
    "\t\t\timage = tf.concat(\n",
    "\t\t\t\t[image[0:y1, :, :][tf.newaxis, ...], middle[tf.newaxis, ...], image[y2:height, :, :][tf.newaxis, ...]],\n",
    "\t\t\t\taxis=1)[0]\n",
    "\n",
    "\t\timage = tf.cast(image, dtype=tf.float32)\n",
    "\t\treturn image\n",
    "\n",
    "\n",
    "def time_shift(img, shift=T_SHIFT):\n",
    "\tif shift > 0:\n",
    "\t\tT = IMAGE_SIZE\n",
    "\t\tP = tf.random.uniform([], 0, 1)\n",
    "\t\tSHIFT = tf.cast(T * P, tf.int32)\n",
    "\t\treturn tf.concat([img[-SHIFT:], img[:-SHIFT]], axis=0)\n",
    "\treturn img\n",
    "\n",
    "\n",
    "def rotate(img, angle=R_ANGLE):\n",
    "\tif angle > 0:\n",
    "\t\tP = tf.random.uniform([], 0, 1)\n",
    "\t\tA = tf.cast(angle * P, tf.float32)\n",
    "\t\treturn tfa.image.rotate(img, A)\n",
    "\treturn img\n",
    "\n",
    "\n",
    "def spector_shift(img, shift=S_SHIFT):\n",
    "\tif shift > 0:\n",
    "\t\tT = IMAGE_SIZE\n",
    "\t\tP = tf.random.uniform([], 0, 1)\n",
    "\t\tSHIFT = tf.cast(T * P, tf.int32)\n",
    "\t\treturn tf.concat([img[:, -SHIFT:], img[:, :-SHIFT]], axis=1)\n",
    "\treturn img\n",
    "\n",
    "\n",
    "def img_aug_f(img):\n",
    "\timg = time_shift(img)\n",
    "\timg = spector_shift(img)\n",
    "\t# img = rotate(img)\n",
    "\treturn img\n",
    "\n",
    "\n",
    "def imgs_aug_f(imgs, batch_size):\n",
    "\t_imgs = []\n",
    "\tDIM = IMAGE_SIZE\n",
    "\tfor j in range(batch_size):\n",
    "\t\t_imgs.append(img_aug_f(imgs[j]))\n",
    "\treturn tf.reshape(tf.stack(_imgs), (batch_size, DIM, DIM, 3))\n",
    "\n",
    "\n",
    "def label_positive_shift(labels):\n",
    "\treturn labels * LABEL_POSITIVE_SHIFT\n",
    "\n",
    "\n",
    "def aug_f(imgs, labels, batch_size):\n",
    "\timgs, label = mixup(imgs, labels, MIXUP_PROB, batch_size)\n",
    "\timgs = imgs_aug_f(imgs, batch_size)\n",
    "\treturn imgs, label_positive_shift(label)\n",
    "\n",
    "\n",
    "def prepare_image(wave, dim=256):\n",
    "\twave = tf.reshape(tf.io.decode_raw(wave, tf.float64), (3, 4096))\n",
    "\tnormalized_waves = []\n",
    "\tfor i in range(3):\n",
    "\t\tnormalized_wave = wave[i] / tf.math.reduce_max(wave[i])\n",
    "\t\tnormalized_waves.append(normalized_wave)\n",
    "\twave = tf.stack(normalized_waves)\n",
    "\twave = tf.cast(wave, tf.float32)\n",
    "\timage = create_cqt_image(wave, HOP_LENGTH)\n",
    "\timage = tf.image.resize(image, size=(dim, dim))\n",
    "\n",
    "\timage = tf.image.random_hue(image=image, max_delta=0.5)\n",
    "\timage = tf.image.random_saturation(image, lower=0.2, upper=0.5)\n",
    "\n",
    "\treturn tf.reshape(image, (dim, dim, 3))\n",
    "\n",
    "\n",
    "def get_dataset(files, batch_size=16, repeat=False, shuffle=False, aug=True, labeled=True, return_image_ids=True):\n",
    "\tds = tf.data.TFRecordDataset(files, num_parallel_reads=AUTO, compression_type=\"GZIP\")\n",
    "\tds = ds.cache()\n",
    "\n",
    "\tif repeat:\n",
    "\t\tds = ds.repeat()\n",
    "\n",
    "\tif shuffle:\n",
    "\t\tds = ds.shuffle(1024 * 2)\n",
    "\t\topt = tf.data.Options()\n",
    "\t\topt.experimental_deterministic = False\n",
    "\t\tds = ds.with_options(opt)\n",
    "\n",
    "\tif labeled:\n",
    "\t\tds = ds.map(read_labeled_tfrecord, num_parallel_calls=AUTO)\n",
    "\telse:\n",
    "\t\tds = ds.map(lambda example: read_unlabeled_tfrecord(example, return_image_ids), num_parallel_calls=AUTO)\n",
    "\n",
    "\tds = ds.batch(batch_size * REPLICAS)\n",
    "\tif aug:\n",
    "\t\tds = ds.map(lambda x, y: aug_f(x, y, batch_size * REPLICAS), num_parallel_calls=AUTO)\n",
    "\tds = ds.prefetch(AUTO)\n",
    "\treturn ds\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-22T14:26:47.747872Z",
     "iopub.execute_input": "2021-08-22T14:26:47.748262Z",
     "iopub.status.idle": "2021-08-22T14:26:47.775523Z",
     "shell.execute_reply.started": "2021-08-22T14:26:47.748224Z",
     "shell.execute_reply": "2021-08-22T14:26:47.773990Z"
    },
    "trusted": true
   },
   "execution_count": 17,
   "outputs": [
    {
     "traceback": [
      "\u001B[0;36m  File \u001B[0;32m\"<tokenize>\"\u001B[0;36m, line \u001B[0;32m138\u001B[0m\n\u001B[0;31m    image = tf.image.random_hue(image, max_delta=0.5)\u001B[0m\n\u001B[0m    ^\u001B[0m\n\u001B[0;31mIndentationError\u001B[0m\u001B[0;31m:\u001B[0m unindent does not match any outer indentation level\n"
     ],
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 138)",
     "output_type": "error"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def build_model(size=256, efficientnet_size=0, weights=\"imagenet\", count=0):\n",
    "\tinputs = tf.keras.layers.Input(shape=(size, size, 3))\n",
    "\n",
    "\tefn_string = f\"EfficientNetB{efficientnet_size}\"\n",
    "\tefn_layer = getattr(efn, efn_string)(input_shape=(size, size, 3), weights=weights, include_top=False)\n",
    "\n",
    "\tx = efn_layer(inputs)\n",
    "\tx = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "\tx = tf.keras.layers.Dropout(0.2)(x)\n",
    "\tx = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\tmodel = tf.keras.Model(inputs=inputs, outputs=x)\n",
    "\n",
    "\tlr_decayed_fn = tf.keras.experimental.CosineDecay(1e-3, count)\n",
    "\topt = tfa.optimizers.AdamW(lr_decayed_fn, learning_rate=1e-4)\n",
    "\tloss = tf.keras.losses.BinaryCrossentropy()\n",
    "\tmodel.compile(optimizer=opt, loss=loss, metrics=[\"AUC\"])\n",
    "\treturn model"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-22T14:20:01.385670Z",
     "iopub.status.idle": "2021-08-22T14:20:01.386252Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def get_lr_callback(batch_size=8, replicas=8):\n",
    "\tlr_start = 1e-4\n",
    "\tlr_max = 0.000015 * replicas * batch_size\n",
    "\tlr_min = 1e-7\n",
    "\tlr_ramp_ep = 3\n",
    "\tlr_sus_ep = 0\n",
    "\tlr_decay = 0.7\n",
    "\n",
    "\tdef lrfn(epoch):\n",
    "\t\tif epoch < lr_ramp_ep:\n",
    "\t\t\tlr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n",
    "\n",
    "\t\telif epoch < lr_ramp_ep + lr_sus_ep:\n",
    "\t\t\tlr = lr_max\n",
    "\n",
    "\t\telse:\n",
    "\t\t\tlr = (lr_max - lr_min) * lr_decay ** (epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n",
    "\n",
    "\t\treturn lr\n",
    "\n",
    "\tlr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=True)\n",
    "\treturn lr_callback"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-22T14:20:01.387713Z",
     "iopub.status.idle": "2021-08-22T14:20:01.388575Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "kf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=1213)\n",
    "oof_pred = []\n",
    "oof_target = []\n",
    "\n",
    "files_train_all = np.array(all_files)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-22T14:20:01.390150Z",
     "iopub.status.idle": "2021-08-22T14:20:01.390792Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for fold, (trn_idx, val_idx) in enumerate(kf.split(files_train_all)):\n",
    "\tfiles_train = files_train_all[trn_idx]\n",
    "\tfiles_valid = files_train_all[val_idx]\n",
    "\n",
    "\tprint(\"=\" * 120)\n",
    "\tprint(f\"Fold {fold}\")\n",
    "\tprint(\"=\" * 120)\n",
    "\n",
    "\ttrain_image_count = count_data_items(files_train)\n",
    "\tvalid_image_count = count_data_items(files_valid)\n",
    "\n",
    "\ttf.keras.backend.clear_session()\n",
    "\tstrategy, tpu_detected = auto_select_accelerator()\n",
    "\twith strategy.scope():\n",
    "\t\tmodel = build_model(\n",
    "\t\t\tsize=IMAGE_SIZE,\n",
    "\t\t\tefficientnet_size=EFFICIENTNET_SIZE,\n",
    "\t\t\tweights=WEIGHTS,\n",
    "\t\t\tcount=train_image_count // BATCH_SIZE // REPLICAS // 4)\n",
    "\n",
    "\tmodel_ckpt = tf.keras.callbacks.ModelCheckpoint(\n",
    "\t\tstr(SAVEDIR / f\"fold{fold}.h5\"), monitor=\"val_auc\", verbose=1, save_best_only=True,\n",
    "\t\tsave_weights_only=True, mode=\"max\", save_freq=\"epoch\"\n",
    "\t)\n",
    "\n",
    "\thistory = model.fit(\n",
    "\t\tget_dataset(files_train, batch_size=BATCH_SIZE, shuffle=True, repeat=True, aug=True),\n",
    "\t\tepochs=EPOCHS,\n",
    "\t\tcallbacks=[model_ckpt, get_lr_callback(BATCH_SIZE, REPLICAS)],\n",
    "\t\tsteps_per_epoch=train_image_count // BATCH_SIZE // REPLICAS // 4,\n",
    "\t\tvalidation_data=get_dataset(files_valid, batch_size=BATCH_SIZE * 4, repeat=False, shuffle=False, aug=False),\n",
    "\t\tverbose=1\n",
    "\t)\n",
    "\n",
    "\tprint(\"Loading best model...\")\n",
    "\tmodel.load_weights(str(SAVEDIR / f\"fold{fold}.h5\"))\n",
    "\n",
    "\tds_valid = get_dataset(files_valid, labeled=False, return_image_ids=False, repeat=True, shuffle=False,\n",
    "\t                       batch_size=BATCH_SIZE * 2, aug=False)\n",
    "\tSTEPS = valid_image_count / BATCH_SIZE / 2 / REPLICAS\n",
    "\tpred = model.predict(ds_valid, steps=STEPS, verbose=0)[:valid_image_count]\n",
    "\toof_pred.append(np.mean(pred.reshape((valid_image_count, 1), order=\"F\"), axis=1))\n",
    "\n",
    "\tds_valid = get_dataset(files_valid, repeat=False, labeled=True, return_image_ids=True, aug=False)\n",
    "\toof_target.append(np.array([target.numpy() for img, target in iter(ds_valid.unbatch())]))\n",
    "\n",
    "\tplt.figure(figsize=(8, 6))\n",
    "\tsns.distplot(oof_pred[-1])\n",
    "\tplt.show()\n",
    "\n",
    "\tplt.figure(figsize=(15, 5))\n",
    "\tplt.plot(\n",
    "\t\tnp.arange(len(history.history[\"auc\"])),\n",
    "\t\thistory.history[\"auc\"],\n",
    "\t\t\"-o\",\n",
    "\t\tlabel=\"Train auc\",\n",
    "\t\tcolor=\"#ff7f0e\")\n",
    "\tplt.plot(\n",
    "\t\tnp.arange(len(history.history[\"auc\"])),\n",
    "\t\thistory.history[\"val_auc\"],\n",
    "\t\t\"-o\",\n",
    "\t\tlabel=\"Val auc\",\n",
    "\t\tcolor=\"#1f77b4\")\n",
    "\n",
    "\tx = np.argmax(history.history[\"val_auc\"])\n",
    "\ty = np.max(history.history[\"val_auc\"])\n",
    "\n",
    "\txdist = plt.xlim()[1] - plt.xlim()[0]\n",
    "\tydist = plt.ylim()[1] - plt.ylim()[0]\n",
    "\n",
    "\tplt.scatter(x, y, s=200, color=\"#1f77b4\")\n",
    "\tplt.text(x - 0.03 * xdist, y - 0.13 * ydist, f\"max auc\\n{y}\", size=14)\n",
    "\n",
    "\tplt.ylabel(\"auc\", size=14)\n",
    "\tplt.xlabel(\"Epoch\", size=14)\n",
    "\tplt.legend(loc=2)\n",
    "\n",
    "\tplt2 = plt.gca().twinx()\n",
    "\tplt2.plot(\n",
    "\t\tnp.arange(len(history.history[\"auc\"])),\n",
    "\t\thistory.history[\"loss\"],\n",
    "\t\t\"-o\",\n",
    "\t\tlabel=\"Train Loss\",\n",
    "\t\tcolor=\"#2ca02c\")\n",
    "\tplt2.plot(\n",
    "\t\tnp.arange(len(history.history[\"auc\"])),\n",
    "\t\thistory.history[\"val_loss\"],\n",
    "\t\t\"-o\",\n",
    "\t\tlabel=\"Val Loss\",\n",
    "\t\tcolor=\"#d62728\")\n",
    "\n",
    "\tx = np.argmin(history.history[\"val_loss\"])\n",
    "\ty = np.min(history.history[\"val_loss\"])\n",
    "\n",
    "\tydist = plt.ylim()[1] - plt.ylim()[0]\n",
    "\n",
    "\tplt.scatter(x, y, s=200, color=\"#d62728\")\n",
    "\tplt.text(x - 0.03 * xdist, y + 0.05 * ydist, \"min loss\", size=14)\n",
    "\n",
    "\tplt.ylabel(\"Loss\", size=14)\n",
    "\tplt.title(f\"Fold {fold + 1} - Image Size {IMAGE_SIZE}, EfficientNetB{EFFICIENTNET_SIZE}\", size=18)\n",
    "\n",
    "\tplt.legend(loc=3)\n",
    "\tplt.savefig(OOFDIR / f\"fig{fold}.png\")\n",
    "\tplt.show()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-22T14:20:01.392181Z",
     "iopub.status.idle": "2021-08-22T14:20:01.392657Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## OOF"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "oof = np.concatenate(oof_pred)\n",
    "true = np.concatenate(oof_target)\n",
    "auc = roc_auc_score(y_true=true, y_score=oof)\n",
    "print(f\"AUC: {auc:.5f}\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-22T14:20:01.393704Z",
     "iopub.status.idle": "2021-08-22T14:20:01.394183Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df = pd.DataFrame({\n",
    "\t\"y_true\": true.reshape(-1),\n",
    "\t\"y_pred\": oof\n",
    "})\n",
    "df.head()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-22T14:20:01.395532Z",
     "iopub.status.idle": "2021-08-22T14:20:01.396014Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "df.to_csv(OOFDIR / f\"oof.csv\", index=False)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-22T14:20:01.397660Z",
     "iopub.status.idle": "2021-08-22T14:20:01.398297Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}